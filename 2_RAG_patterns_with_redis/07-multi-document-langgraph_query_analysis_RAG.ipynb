{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425fb020-e864-40ce-a31f-8da40c73d14b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <div><img src=\"../assets/redis_logo.svg\" style=\"width: 130px\"> </div>\n",
    "    <div style=\"display: inline-block; text-align: center; margin-bottom: 10px;\">\n",
    "        <span style=\"font-size: 36px;\"><b>Multi-document RAG based on LangGraph with Query Understanding and Redis Retrieval Agents</b></span>\n",
    "        <br />\n",
    "    </div>\n",
    "    <br />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00b2501be3b1a0",
   "metadata": {},
   "source": [
    "In [Notebook 06](06-multi-document-langgraph_react_agentic_RAG.ipynb), we explored the **ReAct agent** approach to Retrieval-Augmented Generation (RAG). While it may be suitable for planning in uncertain situations, such as robotics where problem parameters are unknown, it may not be ideal for search applications where tasks and steps are well-defined.\n",
    "\n",
    "In this notebook, we will pivot to a different approach and use **LangGraph** to construct a more deterministic agent that performs the key steps in the search process to answer a user's question. \n",
    "\n",
    "### Key Steps in the Search Process\n",
    "\n",
    "1. **Understanding the Query**: Every search begins with a user query. The primary challenge is understanding the user's intent, which may require personalized and contextual comprehension.\n",
    "2. **Query Expansion**: This involves refining the query, translating it into the target query language, and mapping it into a vector space using an embedding model.\n",
    "3. **Retrieving Relevant Documents**: Once the query is represented in the vector space, the next step is to fetch the most relevant documents.\n",
    "4. **Grading Documents**: After retrieving documents, an LLM is used to grade and score documents based on relevancy.\n",
    "\n",
    "### Approach for This Notebook\n",
    "\n",
    "We will cover each of these steps in detail, demonstrating how to construct an agent using LangGraph to execute them effectively. This agent will be designed to understand user queries, perform query expansion, retrieve relevant documents, and rerank the results to provide accurate and contextually relevant answers to the user's questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468c64492a20099",
   "metadata": {},
   "source": [
    "![Graph](query_understanding_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f1e55f5310c1b",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7fdd37f0036d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T13:08:13.029186Z",
     "start_time": "2024-06-21T13:08:11.834495Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4958a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T13:09:52.052197Z",
     "start_time": "2024-06-21T13:09:52.039803Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load env vars from .env file\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b2270bb-c73a-4862-87d3-57a5b5308b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== ENVIRONMENT VARIABLES ==========\n",
      "Current Directory=/home/ec2-user/SageMaker/financial-rag-workshop/2_RAG_patterns_with_redis\n",
      "Parent Directory=/home/ec2-user/SageMaker/financial-rag-workshop\n",
      "System path=['/home/ec2-user/SageMaker/financial-rag-workshop/helpers', '/home/ec2-user/SageMaker/financial-rag-workshop/helpers', '/home/ec2-user/SageMaker/financial-rag-workshop/helpers', '/home/ec2-user/SageMaker/financial-rag-workshop/helpers', '/home/ec2-user/anaconda3/envs/python3/lib/python310.zip', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/lib-dynload', '', '/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages']\n",
      "---------------------------------\n",
      "Redis URL: redis://localhost:6379\n"
     ]
    }
   ],
   "source": [
    "# set working directory\n",
    "dir_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(dir_path)\n",
    "sys.path.insert(0, f'{parent_directory}/helpers')\n",
    "os.environ[\"ROOT_DIR\"] = parent_directory\n",
    "\n",
    "\n",
    "REDIS_URL = \"redis://localhost:6379\"#os.getenv(\"REDIS_URL\")\n",
    "os.environ[\"REDIS_URL\"] = REDIS_URL\n",
    "\n",
    "print(\"========== ENVIRONMENT VARIABLES ==========\")\n",
    "print(f\"Current Directory={dir_path}\")\n",
    "print(f\"Parent Directory={parent_directory}\")\n",
    "print(f\"System path={sys.path}\")\n",
    "print(\"---------------------------------\")\n",
    "print(f\"Redis URL: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c22327a44dd1c4d",
   "metadata": {},
   "source": [
    "### Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe27d19af62e7bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:04.824902Z",
     "start_time": "2024-06-18T20:35:02.488901Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -r $ROOT_DIR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dc6b74f5a93fb61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:14.138817Z",
     "start_time": "2024-06-18T20:35:10.598980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "from ingestion import get_sec_data, redis_bulk_upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba8eaf10e92f692",
   "metadata": {},
   "source": [
    "### Load embedding model\n",
    "We are using `SentenceTransformerEmbeddings` in this demo and here we specify the cache folder for loading model weights. If you already downloaded the models in a local file system, set this folder here, otherwise the library tries to download the models in this folder if is not locally available.\n",
    "\n",
    "In particular, this models will be downloaded if not present in the cache folder:\n",
    "\n",
    "`models/models--sentence-transformers--all-MiniLM-L6-v2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c405bdf9381db835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:20.082741Z",
     "start_time": "2024-06-18T20:35:20.080118Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the local downloaded sentence transformer models folder\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{parent_directory}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11190e3ee0b4ab1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:21.988151Z",
     "start_time": "2024-06-18T20:35:20.633366Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    cache_folder=os.getenv(\"TRANSFORMERS_CACHE\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bd69c8360baaa0",
   "metadata": {},
   "source": [
    "### Build your Redis index \n",
    "Skip this section if you have already built your index in previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78bbc21dd49fb15f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:33.400040Z",
     "start_time": "2024-06-18T20:35:33.302434Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:40:12 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "source": [
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "\n",
    "# Create a schema\n",
    "index_name = 'langchain'\n",
    "prefix = 'chunk'\n",
    "schema = IndexSchema.from_yaml('sec_index.yaml')\n",
    "\n",
    "# Create a search index from the schema and connect to redis\n",
    "index = SearchIndex(schema, redis_url=REDIS_URL)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ab8cbe7cdea875",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:35:34.057139Z",
     "start_time": "2024-06-18T20:35:34.050783Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Loaded doc info for  110 tickers...\n"
     ]
    }
   ],
   "source": [
    "# Skip if you have already done populated your index.\n",
    "sec_data = get_sec_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b87b9c94d496bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:36:27.486638Z",
     "start_time": "2024-06-18T20:35:35.288607Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 608 10K chunks for ticker=AAPL from AAPL-2022-10K.pdf\n",
      "✅ Loaded 561 10K chunks for ticker=AAPL from AAPL-2023-10K.pdf\n",
      "✅ Loaded 632 10K chunks for ticker=AAPL from AAPL-2021-10K.pdf\n",
      "✅ Loaded 149 earning_call chunks for ticker=AAPL from 2019-Apr-30-AAPL.txt\n",
      "✅ Loaded 149 earning_call chunks for ticker=AAPL from 2017-Jan-31-AAPL.txt\n",
      "✅ Loaded 163 earning_call chunks for ticker=AAPL from 2016-Apr-26-AAPL.txt\n",
      "✅ Loaded 158 earning_call chunks for ticker=AAPL from 2019-Oct-30-AAPL.txt\n",
      "✅ Loaded 146 earning_call chunks for ticker=AAPL from 2020-Jan-28-AAPL.txt\n",
      "✅ Loaded 146 earning_call chunks for ticker=AAPL from 2017-May-02-AAPL.txt\n",
      "✅ Loaded 136 earning_call chunks for ticker=AAPL from 2016-Jul-26-AAPL.txt\n",
      "✅ Loaded 160 earning_call chunks for ticker=AAPL from 2019-Jul-30-AAPL.txt\n",
      "✅ Loaded 145 earning_call chunks for ticker=AAPL from 2018-Nov-01-AAPL.txt\n",
      "✅ Loaded 151 earning_call chunks for ticker=AAPL from 2017-Aug-01-AAPL.txt\n",
      "✅ Loaded 123 earning_call chunks for ticker=AAPL from 2017-Nov-02-AAPL.txt\n",
      "✅ Loaded 143 earning_call chunks for ticker=AAPL from 2019-Jan-29-AAPL.txt\n",
      "✅ Loaded 151 earning_call chunks for ticker=AAPL from 2016-Oct-25-AAPL.txt\n",
      "✅ Loaded 157 earning_call chunks for ticker=AAPL from 2018-Feb-01-AAPL.txt\n",
      "✅ Loaded 167 earning_call chunks for ticker=AAPL from 2020-Jul-30-AAPL.txt\n",
      "✅ Loaded 164 earning_call chunks for ticker=AAPL from 2016-Jan-26-AAPL.txt\n",
      "✅ Loaded 130 earning_call chunks for ticker=AAPL from 2018-May-01-AAPL.txt\n",
      "✅ Loaded 155 earning_call chunks for ticker=AAPL from 2020-Apr-30-AAPL.txt\n",
      "✅ Loaded 142 earning_call chunks for ticker=AAPL from 2018-Jul-31-AAPL.txt\n",
      "✅ Loaded 736 10K chunks for ticker=AMZN from AMZN-2023-10K.pdf\n",
      "✅ Loaded 701 10K chunks for ticker=AMZN from AMZN-2022-10K.pdf\n",
      "✅ Loaded 721 10K chunks for ticker=AMZN from AMZN-2021-10K.pdf\n",
      "✅ Loaded 107 earning_call chunks for ticker=AMZN from 2019-Oct-24-AMZN.txt\n",
      "✅ Loaded 112 earning_call chunks for ticker=AMZN from 2018-Feb-01-AMZN.txt\n",
      "✅ Loaded 127 earning_call chunks for ticker=AMZN from 2019-Jan-31-AMZN.txt\n",
      "✅ Loaded 157 earning_call chunks for ticker=AMZN from 2016-Apr-28-AMZN.txt\n",
      "✅ Loaded 174 earning_call chunks for ticker=AMZN from 2016-Jan-28-AMZN.txt\n",
      "✅ Loaded 114 earning_call chunks for ticker=AMZN from 2020-Apr-30-AMZN.txt\n",
      "✅ Loaded 119 earning_call chunks for ticker=AMZN from 2017-Feb-02-AMZN.txt\n",
      "✅ Loaded 122 earning_call chunks for ticker=AMZN from 2019-Jul-25-AMZN.txt\n",
      "✅ Loaded 115 earning_call chunks for ticker=AMZN from 2020-Jul-30-AMZN.txt\n",
      "✅ Loaded 116 earning_call chunks for ticker=AMZN from 2020-Jan-30-AMZN.txt\n",
      "✅ Loaded 127 earning_call chunks for ticker=AMZN from 2017-Apr-27-AMZN.txt\n",
      "✅ Loaded 116 earning_call chunks for ticker=AMZN from 2017-Oct-26-AMZN.txt\n",
      "✅ Loaded 120 earning_call chunks for ticker=AMZN from 2019-Apr-25-AMZN.txt\n",
      "✅ Loaded 108 earning_call chunks for ticker=AMZN from 2018-Jul-26-AMZN.txt\n",
      "✅ Loaded 112 earning_call chunks for ticker=AMZN from 2018-Apr-26-AMZN.txt\n",
      "✅ Loaded 138 earning_call chunks for ticker=AMZN from 2016-Jul-28-AMZN.txt\n",
      "✅ Loaded 101 earning_call chunks for ticker=AMZN from 2017-Jul-27-AMZN.txt\n",
      "✅ Loaded 111 earning_call chunks for ticker=AMZN from 2016-Oct-27-AMZN.txt\n",
      "✅ Loaded 116 earning_call chunks for ticker=AMZN from 2018-Oct-25-AMZN.txt\n",
      "✅✅✅Loaded a total of 9106 chunks from 6 10Ks and 38 earning calls for 2 tickers.\n"
     ]
    }
   ],
   "source": [
    "redis_bulk_upload(sec_data, index, embeddings, tickers=['AAPL', 'AMZN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e4532",
   "metadata": {},
   "source": [
    "## Redis as a Langchain Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e50c9efe-4abe-42fa-b35a-05eeeede9ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:36:27.618458Z",
     "start_time": "2024-06-18T20:36:27.487480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "vec_schema, main_schema = utils.create_langchain_schemas_from_redis_schema('sec_index.yaml')\n",
    "\n",
    "# Create redis vector store using LangChain\n",
    "rds = LangChainRedis.from_existing_index(\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name,\n",
    "    schema=main_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc76c0d6a83a135",
   "metadata": {},
   "source": [
    "Test if the Redis index is working and returning relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39b95a9507cbf6a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:36:28.056754Z",
     "start_time": "2024-06-18T20:36:27.618990Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 'chunk:AAPL-2021-10K.pdf-7dd23bc0-7f58-421d-a909-8dc9c8358cef', 'chunk_id': 'AAPL-2021-10K.pdf-7dd23bc0-7f58-421d-a909-8dc9c8358cef', 'source_doc': 'AAPL-2021-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='2022 2023 2024 2025 2026 Thereafter\\n\\n$\\n\\nTotal\\n\\n$\\n\\nApple Inc. | 2021 Form 10-K | 48\\n\\n2019\\n\\n3,692 (3,857) 3,735 3,570\\n\\n4,551 2,165 984 405 51 28 8,184\\n\\nContingencies'),\n",
       " Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-fe1160a8-bc62-4d8f-ab34-a14948ad1b24', 'chunk_id': 'AAPL-2022-10K.pdf-fe1160a8-bc62-4d8f-ab34-a14948ad1b24', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='The Company announces new product, service and software offerings at various times during the year. Significant announcements during fiscal 2022 included the following:\\n\\nFirst Quarter 2022:\\n\\n•\\n\\nUpdated MacBook Pro 14” and MacBook Pro 16”, powered by the Apple M1 Pro or M1 Max chip; and Third generation of AirPods.\\n\\nSecond Quarter 2022:\\n\\n• • •')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rds.similarity_search(query=\"Apple in 2022\", k=2, distance_threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d2277-45b2-4ae8-a7d6-62b07fb4a002",
   "metadata": {},
   "source": [
    "## Create components for the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5bf50-92e1-408b-ab21-81211805882c",
   "metadata": {},
   "source": [
    "### Question Answering\n",
    "\n",
    "The question answering step is arguably the simplest yet most important part of the workflow. At this point, we have retrieved relevant context from a source, and now we prompt the LLM to answer the user's question based on this information.\n",
    "\n",
    "**The key objective here is to ensure the answer remains truthful to the provided context, avoiding any hallucinations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae6b410735d14731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:00:46.214536Z",
     "start_time": "2024-06-17T19:00:34.218078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def build_qna_chain():\n",
    "    # LLM\n",
    "    llm = utils.get_chat_llm(temperature=0)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are an assistant for question-answering tasks over financial data. Use the following pieces of retrieved context\n",
    "        to answer the question. If you don't know the answer, just say that you don't know. Do not make anything up. Use three sentences\n",
    "        maximum and keep the answer concise.\n",
    "\n",
    "        Question: {question}\n",
    "        Context: {context}\n",
    "        Answer:\"\"\",\n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    return prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c993954f-3854-4937-a3ef-b8a3093b7299",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VLLM ChatOpenAI using meta-llama/Meta-Llama-3-8B-Instruct served from http://localhost:8000/v1\n"
     ]
    }
   ],
   "source": [
    "# Make the chain!\n",
    "qna_chain = build_qna_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec3886c-007a-4351-85f9-eb11e8e6c9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, Apple's deferred revenue as of September 24, 2022 was $12.4 billion.\n"
     ]
    }
   ],
   "source": [
    "# Test the QnA component\n",
    "\n",
    "question=\"What was Apple's deferred revenue in 2022?\"\n",
    "\n",
    "context=\"\"\"As of September 24, 2022 and September 25, 2021, \n",
    "            the Company had total deferred revenue of $12.4 \n",
    "            billion and $11.9 billion, respectively. As of \n",
    "            September 24, 2022, the Company expects 64% of \n",
    "            total deferred revenue to be realized in less \"\"\"\n",
    "\n",
    "response = qna_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fecb700639afe1",
   "metadata": {},
   "source": [
    "### Query Analysis\n",
    "\n",
    "In this section, we will use our foundation model to analyze user questions and perform several specific tasks.\n",
    "\n",
    "We will take advantage of LangChain's implementation of [structured output parsing](https://python.langchain.com/v0.2/docs/how_to/structured_output/) to handle extraction from the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67437d10-973e-4e46-aaf3-f0dd12da635a",
   "metadata": {},
   "source": [
    "#### Query Decomposer\n",
    "\n",
    "**What problems are we solving?**\n",
    "- Complex questions with embedded sub questions can be challenging for a RAG system to handle\n",
    "- ^^ Especially true if the source data is separate for different questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b944dd-ac8f-4717-a30a-c22880451484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Literal, Optional, List\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def build_decomposer():\n",
    "    # LLM\n",
    "    llm = utils.get_chat_llm(temperature=0, format=\"json\")\n",
    "    \n",
    "    # Structured Output\n",
    "    class QueryDecomposition(BaseModel):\n",
    "        sub_questions: List[str] = Field(\n",
    "            ...,\n",
    "            description=\"A list of natural language questions.\",\n",
    "        )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=QueryDecomposition)\n",
    "    \n",
    "    # Prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"\"\"You are an expert at evaluating compound questions and decomposing them into simpler sub questions / sub problems\n",
    "                that can be resolved independently.\n",
    "                \n",
    "                First, decide if you even need to convert it into sub-questions as it may not be a compound question.\n",
    "                Second, if necessary, decompose a compound question into at max 2-3 sub questions.\n",
    "                \n",
    "                Return the result as a JSON object.\n",
    "\n",
    "                Here are a few examples of the decomposition you can perform:\n",
    "\n",
    "                Question --> \"What is the difference between a 10K and an earnings call transcript?\"\n",
    "                Sub Questions --> [\"What is a 10K document?\", \"What is an earnings call transcript?\"]\n",
    "\n",
    "                Question --> \"How has Microsoft's revenue changed from 2021 to 2022\"\n",
    "                Sub Questions --> [\"What was Microsoft's revenue in 2021?\", \"What was Microsoft's revenue in 2022?\"]\n",
    "                \n",
    "                Question --> \"How many employees work at Apple?\"\n",
    "                Sub Questions --> [\"How many employees work at Apple?\"]\n",
    "\n",
    "                Return the query decomposition as a pure JSON object without any extra content.\n",
    "                Use the following JSON format:\\n{format_instructions}\n",
    "                \"\"\"),\n",
    "            (\"human\", \"Question: {question}. JSON Output: \"),\n",
    "        ]\n",
    "    ).partial(format_instructions=parser.get_format_instructions())\n",
    "    \n",
    "    # Chain\n",
    "    return prompt | llm | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fb3b9fa-7f07-4f26-9136-9b87eca127ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VLLM ChatOpenAI using meta-llama/Meta-Llama-3-8B-Instruct served from http://localhost:8000/v1\n"
     ]
    }
   ],
   "source": [
    "decomposer = build_decomposer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75ba0749-1f9b-43c6-b8cb-48ec91b90bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryDecomposition(sub_questions=['What is deferred revenue?', \"What is Apple's deferred revenue in 2022?\", \"What is Amazon's deferred revenue in 2022?\"])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the deferred revenue of Apple compared to Amazon in 2022?\"\n",
    "decomposer.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81c57d5a-40e9-4476-9bfa-a55a37879bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryDecomposition(sub_questions=['How many employees work at Apple?', 'How many employees work at Amazon?'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposer.invoke({\"question\": \"How many employees work at Apple and Amazon?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13e14d6-e50a-4a4e-8186-89e3ec8ab3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryDecomposition(sub_questions=['What is deferred revenue?', \"What was Apple's deferred revenue in 2022?\"])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposer.invoke({\"question\": \"What was Apple's deferred revenue in 2022?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4462f330-771e-4925-91c7-c228a18d588e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryDecomposition(sub_questions=['Who is Tim Cook?'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposer.invoke({\"question\": \"Who is Tim Cook\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e131175-e2a7-441f-b2e3-ad629f3f92ce",
   "metadata": {},
   "source": [
    "#### Query Analyzer\n",
    "\n",
    "**What problems are we solving?**\n",
    "- We might need to be able to rewrite the question into something more domain-relevant\n",
    "- We need to be able to identify WHICH document set is queried for RAG\n",
    "- We need to be able to identify if the question is related to finance at all (guardrails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b8baedd-e862-4efc-8ba7-5ea6c2e2da28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_analyzer():\n",
    "    # LLM\n",
    "    llm = utils.get_chat_llm(temperature=0, format=\"json\")\n",
    "    \n",
    "    # Structured Output\n",
    "    class QuestionAnalysis(BaseModel):\n",
    "        \"\"\"The analysis and classification of the user's question.\"\"\"\n",
    "\n",
    "        question_relevant: bool = Field(..., description=\"Whether or not the given question is relevant to the finance domain.\")\n",
    "        question_class: Optional[Literal['10K', 'earnings_call']] = Field(None, description=\"If the answer to the question can be found in '10K' filings or 'earnings call' datasets, or if it cannot be classified, default to None\")\n",
    "        new_question: Optional[str] = Field(None, description=\"The rewritten and refined question based on the detected question_class and your knowledge of the finance domain. Default to None if the question is not relevant.\")\n",
    "        note: Optional[str] = Field(None, description=\"Additional notes or explanations regarding the query analysis.\")\n",
    "\n",
    "    # Set up the parser\n",
    "    parser = PydanticOutputParser(pydantic_object=QuestionAnalysis)\n",
    "\n",
    "    # Define the prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert in finance tasked with analyzing and classifying user questions to determine their relevance\n",
    "                and other helpful information.\n",
    "\n",
    "                Return the query analysis as a pure JSON object without extra content. Use the following JSON format:\\n{format_instructions}\"\"\"\n",
    "            ),\n",
    "            (\"human\", \"Question: {question}. JSON:\")\n",
    "        ]\n",
    "    ).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    # Chain\n",
    "    return prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87ab851c-cbca-4fc1-83d0-36d260e43255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VLLM ChatOpenAI using meta-llama/Meta-Llama-3-8B-Instruct served from http://localhost:8000/v1\n"
     ]
    }
   ],
   "source": [
    "analyzer = build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0352a091-8727-4429-8fb4-079d30637286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnalysis(question_relevant=True, question_class='10K', new_question='What is the deferred revenue reported by Apple and Amazon in their 2022 10K filings?', note='The question is relevant to the finance domain and can be answered by analyzing the 10K filings of Apple and Amazon. The new question is a refined version of the original question, focusing on the specific financial metric of interest.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4abf26d92fa5a21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:01:08.132127Z",
     "start_time": "2024-06-17T19:00:57.763076Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnalysis(question_relevant=False, question_class=None, new_question=None, note='The question is not relevant to the finance domain as it is about the mood of an individual (Tim Cook) in a non-financial context (earnings call). The question is more suitable for a psychology or business communication domain.')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.invoke({\"question\": \"what was the mood of Tim Cook in the earning calls of 2022?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbb7f12ecd289a63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:01:19.464677Z",
     "start_time": "2024-06-17T19:01:08.133755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnalysis(question_relevant=False, question_class=None, new_question=None, note='The question appears to be a famous example of a sentence that is grammatically correct but semantically nonsensical, and is not relevant to the finance domain.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.invoke({\"question\": \"Why colorless green ideas are sleeping furiously?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfa82e-fdcf-40b6-a83c-bccf079d09ce",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a286327-a423-4b0b-b544-202537e344c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def redis_retrieval_chain(question: str, filters = None):\n",
    "    #response = decomposer.invoke({\"question\": question})\n",
    "    docs = []\n",
    "    doc_ids = set()\n",
    "    \n",
    "    if filters:\n",
    "        print(\"FILTERS\", filters)\n",
    "        redis_retriever = rds.as_retriever(filters=filters)\n",
    "    else:\n",
    "        redis_retriever = rds.as_retriever()\n",
    "    \n",
    "    new_docs = redis_retriever.get_relevant_documents(question)\n",
    "\n",
    "    for doc in new_docs:\n",
    "        if doc.metadata[\"id\"] not in doc_ids:\n",
    "            docs.append(doc)\n",
    "            doc_ids.add(doc.metadata[\"id\"])\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d82839b3-e56c-4979-a324-3f3577904716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the deferred revenue of Apple compared to Amazon in 2022?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'chunk_id': 'AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='As of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.\\n\\nApple Inc. | 2022 Form 10-K | 37\\n\\n2020\\n\\n137,781 28,622 23,724 30,620 53,768 274,515\\n\\nNote 3 – Financial Instruments'),\n",
       " Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'chunk_id': 'AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Selling, general and administrative expense was relatively ﬂat in 2023 compared to 2022.\\n\\nApple Inc. | 2023 Form 10-K | 23\\n\\n2021\\n\\n105,126 47,710 152,836\\n\\n35.3 % 69.7 % 41.8 %\\n\\n2021\\n\\n21,914\\n\\n6 %\\n\\n21,973\\n\\n6 %\\n\\n43,887\\n\\n12 %\\n\\nProvision for Income Taxes\\n\\nProvision for income taxes, eﬀective tax rate and statutory federal income tax rate for 2023, 2022 and 2021 were as follows (dollars in millions):\\n\\n2023\\n\\n2022\\n\\nProvision for income taxes Eﬀective tax rate Statutory federal income tax rate\\n\\n$'),\n",
       " Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-94bc094b-ef7f-41c3-b94a-22f5878d830f', 'chunk_id': 'AAPL-2023-10K.pdf-94bc094b-ef7f-41c3-b94a-22f5878d830f', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Apple Inc. | 2023 Form 10-K | 34\\n\\nNet sales disaggregated by signiﬁcant products and services for 2023, 2022 and 2021 were as follows (in millions):\\n\\n2023\\n\\n2022\\n\\n2021\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n$\\n\\n200,583 $ 29,357 28,300 39,845 85,200 383,285 $\\n\\n205,489 $ 40,177 29,292 41,241 78,129 394,328 $\\n\\n191,973 35,190 31,862 38,367 68,425 365,817'),\n",
       " Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-f6d8014d-8618-4fa6-b99d-a9f9f7403c65', 'chunk_id': 'AAPL-2022-10K.pdf-f6d8014d-8618-4fa6-b99d-a9f9f7403c65', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Note 2 – Revenue\\n\\nNet sales disaggregated by significant products and services for 2022, 2021 and 2020 were as follows (in millions):\\n\\n2022\\n\\n2021\\n\\n(1)\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(3)\\n\\nTotal net sales\\n\\n(4)\\n\\n(1)(2)\\n\\n$\\n\\n$\\n\\n205,489 $ 40,177 29,292 41,241 78,129 394,328 $\\n\\n191,973 $ 35,190 31,862 38,367 68,425 365,817 $\\n\\n(1) Products net sales include amortization of the deferred value of unspecified software upgrade rights, which are bundled in the')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(question)\n",
    "redis_retrieval_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0b1a0bf5809f9",
   "metadata": {},
   "source": [
    "### Document Grader\n",
    "This is a simple component that determines whether a retrieved document is relevant to user's question or not using a simple strategy. As we demonstrate below, this is not very effective. Firstly, if the documents are presented using a proper embedding model, then they are more likely to be semantically relevant to user's query than this simple strategy. Here we simply want to show this component as a placeholder. We recommend you to either replace this component with a fine-tuned LLM-based reranker or use a Learning To Rank (LTR) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d636fcc416e5b53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:01:26.801105Z",
     "start_time": "2024-06-17T19:01:19.466131Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_document_grader():\n",
    "    # LLM\n",
    "    llm = utils.get_chat_llm(temperature=0, format=\"json\")\n",
    "    \n",
    "    # Structured Output\n",
    "    class DocumentGrade(BaseModel):\n",
    "        \"\"\"The quality of the retrieved document relative to the user question.\"\"\"\n",
    "\n",
    "        relevant: bool = Field(\n",
    "            ...,\n",
    "            description=\"A boolean value indicating whether or not the document is relevant to the user's query. 1 being yes, 0 being no.\"\n",
    "        )\n",
    "        reason: str = Field(\n",
    "            ...,\n",
    "            description=\"A brief explanation for why the decision was made about the document relevancy\"\n",
    "        )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=DocumentGrade)\n",
    "\n",
    "    # Prompt\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"You are an expert in finance, business, and economics that is able to assess the\n",
    "            relevancy between a user question and some context. In other words, your job is to judge\n",
    "            how likely the provided document is able to answer or speak-to the question.\n",
    "\n",
    "            Some guiding principles:\n",
    "            - If the document contains keywords related to the user question, grade it as relevant.\n",
    "            - It does not need to be a stringent test. The goal is to filter out erroneous retrievals.\n",
    "            - Give a binary relevancy score to indicate whether the document is relevant to the question as well as the reason for the decision.\n",
    "\n",
    "            Return the query analysis as a pure JSON object without extra content. Use the following JSON format:\\n{format_instructions}\"\"\",\n",
    "            ),\n",
    "            (\"human\", \"Document: \\n {document} \\n\\n Question: {input}. \\n JSON:\"),\n",
    "        ]\n",
    "    ).partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "    # Chain\n",
    "    return prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0131f7f-5c20-4ae8-8e90-0fc7ee1dc0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created VLLM ChatOpenAI using meta-llama/Meta-Llama-3-8B-Instruct served from http://localhost:8000/v1\n"
     ]
    }
   ],
   "source": [
    "document_grader = build_document_grader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13b1ec0b06e274bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:01:29.288463Z",
     "start_time": "2024-06-17T19:01:26.803482Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentGrade(relevant=False, reason=\"The document does not contain any information about Apple's deferred revenue or a comparison to Amazon's deferred revenue in 2022. The document appears to be a description of Amazon's business model and services, but does not provide financial information or a comparison to another company.\")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_grader.invoke({\"input\": question, \"document\": \"\"\"\n",
    "We serve consumers through our online and physical stores and focus on selection, price, and convenience. We design our\n",
    "stores to enable hundreds of millions of unique products to be sold by us and by third parties across dozens of product categories.\n",
    "Customers access our offerings through our websites, mobile apps, Alexa, devices, streaming, and physically visiting our stores. We\n",
    "also manufacture and sell electronic devices, including Kindle, Fire tablet, Fire TV , Echo, Ring, and other devices, and we develop\n",
    "and produce media content. We seek to offer our customers low prices, fast and free delivery, easy-to-use functionality, and timely\n",
    "customer service. In addition, we offer Amazon Prime, a membership program that includes unlimited free shipping on over 100\n",
    "million items, access to unlimited streaming of tens of thousands of movies and TV episodes, including Amazon Original content,\n",
    "and other benefits.\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1434635cf6709c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:01:30.763736Z",
     "start_time": "2024-06-17T19:01:29.290169Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentGrade(relevant=False, reason=\"The document does not mention Amazon's revenue in 2022. It provides information about Amazon's business model, products, and services, but does not include financial data.\")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_grader.invoke({\"input\": \"Amazon's revenue in 2022\", \"document\": \"\"\"\n",
    "We serve consumers through our online and physical stores and focus on selection, price, and convenience. We design our\n",
    "stores to enable hundreds of millions of unique products to be sold by us and by third parties across dozens of product categories.\n",
    "Customers access our offerings through our websites, mobile apps, Alexa, devices, streaming, and physically visiting our stores. We\n",
    "also manufacture and sell electronic devices, including Kindle, Fire tablet, Fire TV , Echo, Ring, and other devices, and we develop\n",
    "and produce media content. We seek to offer our customers low prices, fast and free delivery, easy-to-use functionality, and timely\n",
    "customer service. In addition, we offer Amazon Prime, a membership program that includes unlimited free shipping on over 100\n",
    "million items, access to unlimited streaming of tens of thousands of movies and TV episodes, including Amazon Original content,\n",
    "and other benefits.\n",
    "\"\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829df8ffee98f5bf",
   "metadata": {},
   "source": [
    "As you can see this grader, grades this document as relevant. It seems to be relevant to Aamzon but there is no information around revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e5bf644e35239",
   "metadata": {},
   "source": [
    "### NER and Filters\n",
    "To increase the precision of the retrieval and limit the search space, it's best to construct filters based on metadata.\n",
    "\n",
    "A simple vector representation often does not cut it.\n",
    "\n",
    "To demonstrate that consider these two queries:\n",
    "- `what was the performance of amzn in 2021?`\n",
    "- `what was the performance of amzn in 2022`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1c6edecf084ee00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:23:04.513112Z",
     "start_time": "2024-06-17T19:23:04.432327Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between<what was the performance of amzn in 2021?> and <what was the performance of amzn in 2022?> ---> 0.9115875851948418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "q1= \"what was the performance of amzn in 2021?\"\n",
    "q2= \"what was the performance of amzn in 2022?\"\n",
    "q3= \"what was the performance of amzn in fiscal year 2022?\" \n",
    "\n",
    "em1 = np.array(embeddings.embed_query(q1))\n",
    "em2 = np.array(embeddings.embed_query(q2))\n",
    "em3 = np.array(embeddings.embed_query(q3))\n",
    "cosine = np.dot(em1,em2)/(np.linalg.norm(em1)*np.linalg.norm(em2))\n",
    "\n",
    "print(f\"Cosine Similarity between<{q1}> and <{q2}> --->\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26f392d442d8008d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:23:07.123591Z",
     "start_time": "2024-06-17T19:23:07.121041Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between<what was the performance of amzn in 2022?> and <what was the performance of amzn in fiscal year 2022?> ---> 0.8379697614770356\n"
     ]
    }
   ],
   "source": [
    "cosine = np.dot(em2,em3)/(np.linalg.norm(em2)*np.linalg.norm(em3))\n",
    "print(f\"Cosine Similarity between<{q2}> and <{q3}> --->\", cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70244a316e5160ea",
   "metadata": {},
   "source": [
    "**The answer to these questions are wildly different.**\n",
    "\n",
    "But the high similarity between two queries will result in documents that might be from different years. However, if you apply a simple date NER and filter the document source year, you will eliminate that problem.\n",
    "\n",
    "> This problem also could appear in geospatial search where a longitude and latitude of two points could point to the same location but with different precision(e.g 12.12412414 is textually different from 12.1 but could be the same lat/lon). So again you can translate to a proper geo-filter (which Redis supports: see an example [here](https://redis.io/learn/howtos/solutions/geo/getting-started)).   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843fb814b811882",
   "metadata": {},
   "source": [
    "We have a built a simple toy NER using spacy, and did a simple filter extraction. It is best to use best-in-class tools that are internal and properietary to the bank. A foundation model is also a candidate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e266c6cdb624601e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:36:53.934540Z",
     "start_time": "2024-06-18T20:36:53.923813Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✅ Loaded doc info for  110 tickers...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'@ticker:{AMZN} | @exchange:{NASDAQ}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from custom_ners import CustomNER\n",
    "\n",
    "ner = CustomNER()\n",
    "\n",
    "def extract_redis_filters(q):\n",
    "    filters = ner.get_redis_filters(q)\n",
    "    return filters\n",
    "\n",
    "extract_redis_filters(\"what was the performance of amzn in 2021 in nasdaq?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b91bce77c915d3b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T20:36:55.778296Z",
     "start_time": "2024-06-18T20:36:55.770470Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@company_name:{APPLE INC}'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_redis_filters(\"what was the performance of Apple Inc in 2021?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2fc571ea60f6c",
   "metadata": {},
   "source": [
    "# Putting it all together: build RAG agent as a graph\n",
    "Now that we have all the components for our RAG logic we will connect them through a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f03f9e92f8596f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:23:22.539915Z",
     "start_time": "2024-06-17T19:23:22.534793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Annotated, TypedDict, Union, Sequence, List\n",
    "\n",
    "\n",
    "# AgentState represents the contents shared between processing nodes in the graph\n",
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    filters: str\n",
    "    question_relevant: bool\n",
    "    question_class: str\n",
    "    alternate_question: str\n",
    "    question_note: str\n",
    "    rewrite_num: int\n",
    "    generation: str\n",
    "    documents: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "993ba7ced09fdc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:23:23.309828Z",
     "start_time": "2024-06-17T19:23:23.297705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "MAX_RETRY_COUNT = 2\n",
    "MAX_TOKEN_LIMIT = 1000 #char\n",
    "TOP_DOC_LIMIT = 2\n",
    "\n",
    "\n",
    "### Edges\n",
    "def check_retrieval_relevancy(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question or not.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    retries = state[\"rewrite_num\"]\n",
    "\n",
    "    # Score each doc\n",
    "    relevant_docs = []\n",
    "    for doc in documents:\n",
    "        document_grade: DocumentGrade = document_grader.invoke({\"input\": question, \"document\": doc})\n",
    "\n",
    "        if document_grade.relevant:\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            relevant_docs.append(doc)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "\n",
    "    if (len(documents) - len(relevant_docs)) <= 2:\n",
    "        state[\"documents\"] = relevant_docs\n",
    "        return \"generate\"\n",
    "    elif retries < MAX_RETRY_COUNT:\n",
    "        return \"rewrite\"\n",
    "    elif retries >= MAX_RETRY_COUNT:\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def check_question_relevancy(state) -> Literal[\"generate\", \"retrieve\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the asked question is relevant to our domain and if retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the question is relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    question_relevant = state[\"question_relevant\"]\n",
    "    if not question_relevant:\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"retrieve\"\n",
    "\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def query_understanding_node(state):\n",
    "    \"\"\"\n",
    "    Analyzes the input query for better retrieval.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the result of query analysis\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n---QUERY Analysis---\")\n",
    "\n",
    "    def combine_filters(inferred_filters, doc_type_filter=\"10K\", filter_strategy=\"AND\"):\n",
    "        if inferred_filters is None:\n",
    "            return \"@doc_type:{\"+f\"{doc_type_filter}\"+\"}\"\n",
    "        else:\n",
    "            return \"@doc_type:{\"+f\"{doc_type_filter}\"+\"} \" + filter_strategy +f\" ({inferred_filters})\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    rewrite_num = state[\"rewrite_num\"]\n",
    "\n",
    "    if rewrite_num is None:\n",
    "        rewrite_num = 1\n",
    "    else:\n",
    "        rewrite_num = int(state[\"rewrite_num\"]) + 1\n",
    "\n",
    "    query_filters = extract_redis_filters(question)\n",
    "    question_analysis: QuestionAnalysis = analyzer.invoke({\"question\": question})\n",
    "    print(f\"---QUERY rewrite---question_analysis={question_analysis}\")\n",
    "\n",
    "    if question_analysis.question_class is not None:\n",
    "        print(f\"---Question is related to: {question_analysis.question_class}---\")\n",
    "        applied_filters = combine_filters(query_filters, doc_type_filter=question_analysis.question_class)\n",
    "    else:\n",
    "        applied_filters = combine_filters(query_filters)\n",
    "\n",
    "    return {\n",
    "        \"filters\": applied_filters,\n",
    "        \"question_class\": question_analysis.question_class,\n",
    "        \"question_relevant\": question_analysis.question_relevant,\n",
    "        \"alternate_question\": question_analysis.new_question,\n",
    "        \"question_note\": question_analysis.note,\n",
    "        \"rewrite_num\": rewrite_num\n",
    "    }\n",
    "\n",
    "\n",
    "def redis_retriever_node(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from Redis.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"\\n---RETRIEVE FROM REDIS---\")\n",
    "    question = state[\"question\"]\n",
    "    alternate_question = state[\"alternate_question\"]\n",
    "    retries = state[\"rewrite_num\"]\n",
    "    filters = state[\"filters\"]\n",
    "\n",
    "    print(f\"---RETRIEVE FROM REDIS query={question} alternate_question={alternate_question} retries={retries}\")\n",
    "\n",
    "    if alternate_question is not None and retries > 1:\n",
    "        question = alternate_question\n",
    "    \n",
    "    if filters:\n",
    "        print(\"FILTERS\", filters)\n",
    "        redis_retriever = rds.as_retriever(filters=filters)\n",
    "    else:\n",
    "        redis_retriever = rds.as_retriever()\n",
    "    \n",
    "    docs = redis_retriever.get_relevant_documents(question)\n",
    "\n",
    "    return {\"documents\": docs}\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    companies = defaultdict(list)\n",
    "    for doc in docs:\n",
    "        company_name = doc.metadata.get(\"company_name\", \"Additional Context\")\n",
    "        companies[company_name].append(str(doc.page_content).replace(\"\\n\", \" \"))\n",
    "\n",
    "    result = []\n",
    "    for company, contents in companies.items():\n",
    "        if company == \"Additional Context\":\n",
    "            result.append(company)\n",
    "        else:\n",
    "            result.append(f\"Company: {company}\")\n",
    "        result.append(\"\\n\".join(contents))\n",
    "\n",
    "    return \"\\n\\n\".join(result)\n",
    "\n",
    "\n",
    "def generate_node(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n---GENERATE---\")\n",
    "    final_docs = state[\"documents\"]\n",
    "    final_question = state[\"alternate_question\"] or state[\"question\"] \n",
    "    question_relevant = state[\"question_relevant\"]\n",
    "    note = state[\"question_note\"]\n",
    "\n",
    "    final_context = \"\"\n",
    "    if not question_relevant:\n",
    "        final_context = \"Your question does not seem to be relevant to finance. Please only ask questions that are relevant to financials of companies that are usually reported in 10K or earning calls.\"\n",
    "        if note is not None:\n",
    "            final_context = final_context + f\"\\n\\n{note}\"\n",
    "    elif question_relevant and final_docs is not None and len(final_docs) > 0:\n",
    "        final_context = format_docs(final_docs)\n",
    "\n",
    "    print(f\"\\nDEBUG:GENERATE === question={final_question}\")\n",
    "    print(f\"DEBUG:GENERATE === context={final_context}\")\n",
    "\n",
    "    # Run Gen LLM\n",
    "    generated_answer = qna_chain.invoke({\"context\": final_context, \"question\": final_question})\n",
    "\n",
    "    print(f\"DEBUG:GENERATE === generation={generated_answer}\")\n",
    "    return {\"messages\": [generated_answer], \"generation\": generated_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2acd602638ce906",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:23:25.109986Z",
     "start_time": "2024-06-17T19:23:24.164238Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"query_analysis_node\", query_understanding_node)\n",
    "workflow.add_node(\"redis_retriever_node\", redis_retriever_node)\n",
    "workflow.add_node(\"generate_node\", generate_node)\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"redis_retriever_node\",\n",
    "    check_retrieval_relevancy,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"rewrite\": \"query_analysis_node\",\n",
    "        \"generate\": \"generate_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_analysis_node\",\n",
    "    check_question_relevancy,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"retrieve\": \"redis_retriever_node\",\n",
    "        \"generate\": \"generate_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"generate_node\", END)\n",
    "\n",
    "workflow.set_entry_point(\"query_analysis_node\")\n",
    "\n",
    "# Compile\n",
    "graphapp = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graphapp.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7823529303b98dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:25:12.910129Z",
     "start_time": "2024-06-17T19:23:26.055153Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---QUERY Analysis---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---QUERY rewrite---question_analysis=question_relevant=True question_class='10K' new_question='What is the deferred revenue reported by Apple in their 2022 annual report?' note=\"The question is relevant to the finance domain and can be answered by analyzing Apple's 10K filings. The rewritten question is more specific and accurate.\"\n",
      "---Question is related to: 10K---\n",
      "Output from node 'query_analysis_node':\n",
      "---\n",
      "{'filters': '@doc_type:{10K}', 'question_relevant': True, 'question_class': '10K', 'alternate_question': 'What is the deferred revenue reported by Apple in their 2022 annual report?', 'question_note': \"The question is relevant to the finance domain and can be answered by analyzing Apple's 10K filings. The rewritten question is more specific and accurate.\", 'rewrite_num': 1}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---RETRIEVE FROM REDIS---\n",
      "---RETRIEVE FROM REDIS query=What was the deferred revenue of Apple in 2022? alternate_question=What is the deferred revenue reported by Apple in their 2022 annual report? retries=1\n",
      "FILTERS @doc_type:{10K}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "Output from node 'redis_retriever_node':\n",
      "---\n",
      "{'documents': [Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'chunk_id': 'AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='As of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.\\n\\nApple Inc. | 2022 Form 10-K | 37\\n\\n2020\\n\\n137,781 28,622 23,724 30,620 53,768 274,515\\n\\nNote 3 – Financial Instruments'), Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'chunk_id': 'AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Selling, general and administrative expense was relatively ﬂat in 2023 compared to 2022.\\n\\nApple Inc. | 2023 Form 10-K | 23\\n\\n2021\\n\\n105,126 47,710 152,836\\n\\n35.3 % 69.7 % 41.8 %\\n\\n2021\\n\\n21,914\\n\\n6 %\\n\\n21,973\\n\\n6 %\\n\\n43,887\\n\\n12 %\\n\\nProvision for Income Taxes\\n\\nProvision for income taxes, eﬀective tax rate and statutory federal income tax rate for 2023, 2022 and 2021 were as follows (dollars in millions):\\n\\n2023\\n\\n2022\\n\\nProvision for income taxes Eﬀective tax rate Statutory federal income tax rate\\n\\n$'), Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-94bc094b-ef7f-41c3-b94a-22f5878d830f', 'chunk_id': 'AAPL-2023-10K.pdf-94bc094b-ef7f-41c3-b94a-22f5878d830f', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Apple Inc. | 2023 Form 10-K | 34\\n\\nNet sales disaggregated by signiﬁcant products and services for 2023, 2022 and 2021 were as follows (in millions):\\n\\n2023\\n\\n2022\\n\\n2021\\n\\niPhone (1) Mac iPad Wearables, Home and Accessories Services\\n\\n(1)\\n\\n(1)\\n\\n(2)\\n\\nTotal net sales\\n\\n(1)\\n\\n$\\n\\n$\\n\\n200,583 $ 29,357 28,300 39,845 85,200 383,285 $\\n\\n205,489 $ 40,177 29,292 41,241 78,129 394,328 $\\n\\n191,973 35,190 31,862 38,367 68,425 365,817'), Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-8d0bb4df-a967-46fe-ac21-239f156046f8', 'chunk_id': 'AAPL-2022-10K.pdf-8d0bb4df-a967-46fe-ac21-239f156046f8', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='The year-over-year growth in selling, general and administrative expense in 2022 was driven primarily by increases in headcount- related expenses, advertising and professional services.\\n\\nApple Inc. | 2022 Form 10-K | 23\\n\\n2020\\n\\n69,461 35,495 104,956\\n\\n31.5 % 66.0 % 38.2 %\\n\\n2020 18,752\\n\\n7 %\\n\\n19,916\\n\\n7 %\\n\\n38,668\\n\\n14 %\\n\\nOther Income/(Expense), Net\\n\\nOther income/(expense), net (“OI&E”) for 2022, 2021 and 2020 was as follows (dollars in millions):\\n\\n2022\\n\\nChange\\n\\n2021\\n\\nChange')]}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---QUERY Analysis---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---QUERY rewrite---question_analysis=question_relevant=True question_class='10K' new_question='What is the deferred revenue reported by Apple in their 2022 annual report?' note=\"The question is relevant to the finance domain and can be answered by analyzing Apple's 10K filings. The rewritten question is more specific and accurate.\"\n",
      "---Question is related to: 10K---\n",
      "Output from node 'query_analysis_node':\n",
      "---\n",
      "{'filters': '@doc_type:{10K}', 'question_relevant': True, 'question_class': '10K', 'alternate_question': 'What is the deferred revenue reported by Apple in their 2022 annual report?', 'question_note': \"The question is relevant to the finance domain and can be answered by analyzing Apple's 10K filings. The rewritten question is more specific and accurate.\", 'rewrite_num': 2}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---RETRIEVE FROM REDIS---\n",
      "---RETRIEVE FROM REDIS query=What was the deferred revenue of Apple in 2022? alternate_question=What is the deferred revenue reported by Apple in their 2022 annual report? retries=2\n",
      "FILTERS @doc_type:{10K}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "Output from node 'redis_retriever_node':\n",
      "---\n",
      "{'documents': [Document(metadata={'id': 'chunk:AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'chunk_id': 'AAPL-2022-10K.pdf-543defe5-f567-46db-af30-504c240f3efb', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='As of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.\\n\\nApple Inc. | 2022 Form 10-K | 37\\n\\n2020\\n\\n137,781 28,622 23,724 30,620 53,768 274,515\\n\\nNote 3 – Financial Instruments'), Document(metadata={'id': 'chunk:AAPL-2021-10K.pdf-5e738fc6-86e4-46ac-bce9-feb496db6fc7', 'chunk_id': 'AAPL-2021-10K.pdf-5e738fc6-86e4-46ac-bce9-feb496db6fc7', 'source_doc': 'AAPL-2021-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='The Company has elected to record revenue net of taxes collected from customers that are remitted to governmental authorities, with the collected taxes recorded within other current liabilities until remitted to the relevant government authority.\\n\\nApple Inc. | 2021 Form 10-K | 36\\n\\nDeferred Revenue'), Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'chunk_id': 'AAPL-2023-10K.pdf-28ab7da9-7f2a-4e66-bd43-5f9f0dbf4568', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='Selling, general and administrative expense was relatively ﬂat in 2023 compared to 2022.\\n\\nApple Inc. | 2023 Form 10-K | 23\\n\\n2021\\n\\n105,126 47,710 152,836\\n\\n35.3 % 69.7 % 41.8 %\\n\\n2021\\n\\n21,914\\n\\n6 %\\n\\n21,973\\n\\n6 %\\n\\n43,887\\n\\n12 %\\n\\nProvision for Income Taxes\\n\\nProvision for income taxes, eﬀective tax rate and statutory federal income tax rate for 2023, 2022 and 2021 were as follows (dollars in millions):\\n\\n2023\\n\\n2022\\n\\nProvision for income taxes Eﬀective tax rate Statutory federal income tax rate\\n\\n$'), Document(metadata={'id': 'chunk:AAPL-2023-10K.pdf-5ba4a41e-0be1-4c49-8f8a-88205c552951', 'chunk_id': 'AAPL-2023-10K.pdf-5ba4a41e-0be1-4c49-8f8a-88205c552951', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}, page_content='As of September 30, 2023 and September 24, 2022, the Company had total deferred revenue of $12.1 billion and $12.4 billion, respectively. As of September 30, 2023, the Company expects 67% of total deferred revenue to be realized in less than a year, 25% within one-to-two years, 7% within two-to-three years and 1% in greater than three years.\\n\\nNote 3 – Earnings Per Share')]}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---GENERATE---\n",
      "\n",
      "DEBUG:GENERATE === question=What is the deferred revenue reported by Apple in their 2022 annual report?\n",
      "DEBUG:GENERATE === context=Company: APPLE INC\n",
      "\n",
      "As of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.  Apple Inc. | 2022 Form 10-K | 37  2020  137,781 28,622 23,724 30,620 53,768 274,515  Note 3 – Financial Instruments\n",
      "The Company has elected to record revenue net of taxes collected from customers that are remitted to governmental authorities, with the collected taxes recorded within other current liabilities until remitted to the relevant government authority.  Apple Inc. | 2021 Form 10-K | 36  Deferred Revenue\n",
      "Selling, general and administrative expense was relatively ﬂat in 2023 compared to 2022.  Apple Inc. | 2023 Form 10-K | 23  2021  105,126 47,710 152,836  35.3 % 69.7 % 41.8 %  2021  21,914  6 %  21,973  6 %  43,887  12 %  Provision for Income Taxes  Provision for income taxes, eﬀective tax rate and statutory federal income tax rate for 2023, 2022 and 2021 were as follows (dollars in millions):  2023  2022  Provision for income taxes Eﬀective tax rate Statutory federal income tax rate  $\n",
      "As of September 30, 2023 and September 24, 2022, the Company had total deferred revenue of $12.1 billion and $12.4 billion, respectively. As of September 30, 2023, the Company expects 67% of total deferred revenue to be realized in less than a year, 25% within one-to-two years, 7% within two-to-three years and 1% in greater than three years.  Note 3 – Earnings Per Share\n",
      "DEBUG:GENERATE === generation=According to the provided context, Apple reported total deferred revenue of $12.4 billion as of September 24, 2022.\n",
      "Output from node 'generate_node':\n",
      "---\n",
      "{'generation': 'According to the provided context, Apple reported total deferred revenue of $12.4 billion as of September 24, 2022.'}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"question\": \"What was the deferred revenue of Apple in 2022?\",\n",
    "}\n",
    "\n",
    "for output in graphapp.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34f4fb3c09949739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T19:28:13.974034Z",
     "start_time": "2024-06-17T19:27:51.925269Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---QUERY Analysis---\n",
      "---QUERY rewrite---question_analysis=question_relevant=False question_class=None new_question=None note='The question appears to be a famous example of a sentence that is grammatically correct but semantically nonsensical, and is not relevant to the finance domain.'\n",
      "Output from node 'query_analysis_node':\n",
      "---\n",
      "{'filters': '@doc_type:{10K}', 'question_relevant': False, 'question_class': None, 'alternate_question': None, 'question_note': 'The question appears to be a famous example of a sentence that is grammatically correct but semantically nonsensical, and is not relevant to the finance domain.', 'rewrite_num': 1}\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---GENERATE---\n",
      "\n",
      "DEBUG:GENERATE === question=Why colorless green ideas are furiously sleeping?\n",
      "DEBUG:GENERATE === context=Your question does not seem to be relevant to finance. Please only ask questions that are relevant to financials of companies that are usually reported in 10K or earning calls.\n",
      "\n",
      "The question appears to be a famous example of a sentence that is grammatically correct but semantically nonsensical, and is not relevant to the finance domain.\n",
      "DEBUG:GENERATE === generation=I don't know the answer to this question as it appears to be a linguistic example rather than a financial query. The context provided indicates that the question is not relevant to financial data typically reported in 10K or earnings calls.\n",
      "Output from node 'generate_node':\n",
      "---\n",
      "{'generation': \"I don't know the answer to this question as it appears to be a linguistic example rather than a financial query. The context provided indicates that the question is not relevant to financial data typically reported in 10K or earnings calls.\"}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs2 = {\n",
    "    \"question\": \"Why colorless green ideas are furiously sleeping?\"\n",
    "}\n",
    "\n",
    "for output2 in graphapp.stream(inputs2):\n",
    "    for key2, value2 in output2.items():\n",
    "        print(f\"Output from node '{key2}':\")\n",
    "        print(\"---\")\n",
    "        print(value2)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59f853531650fd",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Multiple index routing scenarios where based on the detected `question_class` we run retrieval queries on different Redis indices.\n",
    "- Implement proper query decomposition and multi query retrieval.\n",
    "- Test parent document retrieval in the context of agentic RAG.\n",
    "- Implement a semantic caching strategy in Redis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
