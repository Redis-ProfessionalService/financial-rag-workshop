{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425fb020-e864-40ce-a31f-8da40c73d14b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <div><img src=\"../assets/redis_logo.svg\" style=\"width: 130px\"> </div>\n",
    "    <div style=\"display: inline-block; text-align: center; margin-bottom: 10px;\">\n",
    "        <span style=\"font-size: 36px;\"><b>Multi-document RAG based on LangGraph with Query Understanding and Redis Retrieval Agents using Ollama</b></span>\n",
    "        <br />\n",
    "    </div>\n",
    "    <br />\n",
    "</div>\n",
    "\n",
    "# \n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we saw in notebook 06, a React agentic approach to search and treating a Redis retriever as a tool, and moreover leaving the reasoning to an LLM could lead to some uncertainty. A react agentic approach might be a better approach for planning in an uncertain situation (maybe a robotic application where parameters of the problem are unknown) and not for a search application where the tasks and steps to take are very well-defined. Any search starts with a query by a user. The first task is to understand the query or user's question. The hardest part is to understand the intent of the user which might need some personalized and contextual understanding of the user - which we will not address here. Nevertheless, the first component of a search application is query understanding. The second component is constructing a refined query via query augmentation, translation of user's query into a combination of target query language and mapping the query into a vector space using an embedding model. After query translation and representation in a vector space, it is time to retrieve the relevant documents. Here we showcase the Redis hybrid search capabilities and its integration in langchain. After fetching the most relevant documents, usually reranking happens (and by reranking we don't necessarily mean Semantic reranking - one could apply business logic in this step; for example, Ad injection and/or reordering based on business and user's context such as location or session information). In this notebook we don't use a reranker but employ a very simple document relevancy checker using the same `llama3` LLM. However, in a more realistic scenario, one should use task-specific or fine-tuned LLMs for each of these steps or even use the existing models or pipelines (query classifier, Learning To Rank, etc.). In fact, it might be a requirement that some models need to run faster/cheaper or be more explainable or certified for complaince reasons (such as Logistic Regression, decision trees, MaxEnt etc.) Please plug in any of such models instead of our generic LLM-based component if needed.      ",
   "id": "7c00b2501be3b1a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment Setup",
   "id": "c54f1e55f5310c1b"
  },
  {
   "cell_type": "code",
   "id": "e4958a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:02.892660Z",
     "start_time": "2024-06-13T18:15:02.882373Z"
    }
   },
   "source": [
    "import os\n",
    "import warnings\n",
    "import dotenv\n",
    "# mute warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# load env vars from .env file\n",
    "dotenv.load_dotenv()\n",
    "dir_path = os.getcwd()\n",
    "parent_directory = os.path.dirname(dir_path)\n",
    "os.environ[\"ROOT_DIR\"] = parent_directory\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\")\n",
    "print(dir_path)\n",
    "print(parent_directory)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/2_RAG_patterns_with_redis\n",
      "/Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Install Python Dependencies",
   "id": "2c22327a44dd1c4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:05.854432Z",
     "start_time": "2024-06-13T18:15:02.966906Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -r $ROOT_DIR/requirements.txt",
   "id": "fe27d19af62e7bc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 1)) (1.0.1)\r\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 2)) (0.7.0)\r\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (0.2.1)\r\n",
      "Requirement already satisfied: langchain-community in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 4)) (0.2.1)\r\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (2.7.0)\r\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 7)) (2.2.2)\r\n",
      "Requirement already satisfied: pdf2image in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 8)) (1.17.0)\r\n",
      "Requirement already satisfied: spacy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (3.7.4)\r\n",
      "Requirement already satisfied: langgraph in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 10)) (0.0.59)\r\n",
      "Requirement already satisfied: redis in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 11)) (5.0.3)\r\n",
      "Requirement already satisfied: redisvl in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 12)) (0.1.3)\r\n",
      "Requirement already satisfied: langchain-openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 13)) (0.1.8)\r\n",
      "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (1.30.5)\r\n",
      "Requirement already satisfied: unstructured[pdf] in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from -r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.14.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 2)) (2024.4.16)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tiktoken->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 2)) (2.31.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (3.9.5)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (0.2.2)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (0.2.0)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (0.1.65)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (2.7.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (8.2.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-community->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 4)) (0.6.6)\r\n",
      "Requirement already satisfied: chardet in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (5.2.0)\r\n",
      "Requirement already satisfied: filetype in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.2.0)\r\n",
      "Requirement already satisfied: python-magic in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.4.27)\r\n",
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (5.2.2)\r\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.8.1)\r\n",
      "Requirement already satisfied: tabulate in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.9.0)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.12.3)\r\n",
      "Requirement already satisfied: emoji in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.12.1)\r\n",
      "Requirement already satisfied: python-iso639 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2024.4.27)\r\n",
      "Requirement already satisfied: langdetect in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.0.9)\r\n",
      "Requirement already satisfied: rapidfuzz in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.9.2)\r\n",
      "Requirement already satisfied: backoff in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.2.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.11.0)\r\n",
      "Requirement already satisfied: unstructured-client in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.22.0)\r\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.16.0)\r\n",
      "Requirement already satisfied: onnx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.16.1)\r\n",
      "Requirement already satisfied: pdfminer.six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (20231228)\r\n",
      "Requirement already satisfied: pikepdf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (8.15.1)\r\n",
      "Requirement already satisfied: pillow-heif in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.16.0)\r\n",
      "Requirement already satisfied: pypdf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.2.0)\r\n",
      "Requirement already satisfied: pytesseract in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.3.10)\r\n",
      "Requirement already satisfied: google-cloud-vision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.7.2)\r\n",
      "Requirement already satisfied: effdet in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.4.1)\r\n",
      "Requirement already satisfied: unstructured-inference==0.7.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.7.33)\r\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.3.12)\r\n",
      "Requirement already satisfied: layoutparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.3.4)\r\n",
      "Requirement already satisfied: python-multipart in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.0.9)\r\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.22.2)\r\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.9.0.80)\r\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.18.0)\r\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.9.0)\r\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.3.0)\r\n",
      "Requirement already satisfied: timm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.0.3)\r\n",
      "Requirement already satisfied: transformers>=4.25.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.40.0)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (4.66.2)\r\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (1.4.2)\r\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (1.13.0)\r\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (10.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 7)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 7)) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 7)) (2024.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (8.2.3)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (0.3.4)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (0.9.4)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (6.4.0)\r\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (3.1.3)\r\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (70.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (23.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (3.4.0)\r\n",
      "Requirement already satisfied: coloredlogs in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from redisvl->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 12)) (15.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (4.3.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (0.27.0)\r\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (1.3.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (1.9.4)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (3.7)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 4)) (3.21.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 4)) (0.9.0)\r\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 14)) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.13.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2024.3.1)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (1.33)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (1.2.0)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (3.10.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3,>=1->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (2.18.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 7)) (1.16.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 2)) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 2)) (2.2.1)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (0.7.11)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (0.1.4)\r\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.4.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer<0.10.0,>=0.3.0->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from weasel<0.4.0,>=0.1.0->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (0.16.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.5)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from coloredlogs->redisvl->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 12)) (10.0)\r\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from effdet->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.18.0)\r\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from effdet->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.0.7)\r\n",
      "Requirement already satisfied: omegaconf>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from effdet->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.3.0)\r\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.19.0)\r\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.29.0)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.23.0)\r\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.25.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (2.1.5)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pdfminer.six->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (42.0.7)\r\n",
      "Requirement already satisfied: Deprecated in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pikepdf->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.2.14)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn->sentence-transformers->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 6)) (3.4.0)\r\n",
      "Requirement already satisfied: deepdiff>=6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (7.0.1)\r\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.0.6)\r\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from unstructured-client->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.0.0)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.16.0)\r\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from deepdiff>=6.0->unstructured-client->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.1.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.63.0)\r\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.64.0)\r\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.62.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (5.3.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.4.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.9)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 3)) (2.4)\r\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 9)) (1.1.1)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.9.3)\r\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (24.3.25)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.52.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (3.1.2)\r\n",
      "Requirement already satisfied: iopath in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from layoutparser->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.1.10)\r\n",
      "Requirement already satisfied: pdfplumber in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from layoutparser->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.11.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (1.3.0)\r\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.22)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (0.6.0)\r\n",
      "Requirement already satisfied: portalocker in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from iopath->layoutparser->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (2.8.2)\r\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pdfplumber->layoutparser->unstructured-inference==0.7.33->unstructured[pdf]->-r /Users/rouzbeh.farahmand/PycharmProjects/boa-financial-rag-workshop/requirements.txt (line 5)) (4.30.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### SentenceTransformerEmbeddings Models Cache folder\n",
    "We are using `SentenceTransformerEmbeddings` in this demo and here we specify the cache folder. If you already downloaded the models in a local file system, set this folder here, otherwise the library tries to download the models in this folder if not available locally.\n",
    "\n",
    "In particular, this models will be downloaded if not present in the cache folder:\n",
    "\n",
    "models/models--sentence-transformers--all-MiniLM-L6-v2"
   ],
   "id": "9ba8eaf10e92f692"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:05.858288Z",
     "start_time": "2024-06-13T18:15:05.855693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#setting the local downloaded sentence transformer models folder\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = f\"{parent_directory}/models\""
   ],
   "id": "c405bdf9381db835",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:06.782372Z",
     "start_time": "2024-06-13T18:15:05.858866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                           cache_folder=os.getenv(\"TRANSFORMERS_CACHE\", f\"{parent_directory}/models\"))"
   ],
   "id": "11190e3ee0b4ab1d",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Build your Redis index \n",
    "Skip this section if you have already built your index in previous notebook.\n"
   ],
   "id": "30bd69c8360baaa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:06.956043Z",
     "start_time": "2024-06-13T18:15:06.783479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "from redis import Redis\n",
    "index_name = 'langchain'\n",
    "prefix = 'chunk'\n",
    "schema = IndexSchema.from_yaml('sec_index.yaml')\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "# create an index from schema and the client\n",
    "index = SearchIndex(schema, client)\n",
    "index.create(overwrite=True, drop=True)"
   ],
   "id": "78bbc21dd49fb15f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:15:06 redisvl.index.index INFO   Index already exists, overwriting.\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:06.969654Z",
     "start_time": "2024-06-13T18:15:06.956579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Skip if you have already done populated your index.\n",
    "from ingestion import get_sec_data\n",
    "from ingestion import redis_bulk_upload\n",
    "\n",
    "sec_data = get_sec_data()"
   ],
   "id": "c1ab8cbe7cdea875",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded doc info for  110 tickers...\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:55.514134Z",
     "start_time": "2024-06-13T18:15:06.970818Z"
    }
   },
   "cell_type": "code",
   "source": "redis_bulk_upload(sec_data, index, embeddings, tickers=['AAPL','AMZN'])",
   "id": "5b87b9c94d496bc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 108 10K chunks for ticker=AAPL from AAPL-2021-10K.pdf\n",
      " Loaded 94 10K chunks for ticker=AAPL from AAPL-2023-10K.pdf\n",
      " Loaded 103 10K chunks for ticker=AAPL from AAPL-2022-10K.pdf\n",
      " Loaded 27 earning_call chunks for ticker=AAPL from 2018-May-01-AAPL.txt\n",
      " Loaded 31 earning_call chunks for ticker=AAPL from 2019-Oct-30-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jan-26-AAPL.txt\n",
      " Loaded 31 earning_call chunks for ticker=AAPL from 2020-Jul-30-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2017-Aug-01-AAPL.txt\n",
      " Loaded 29 earning_call chunks for ticker=AAPL from 2020-Jan-28-AAPL.txt\n",
      " Loaded 34 earning_call chunks for ticker=AAPL from 2016-Apr-26-AAPL.txt\n",
      " Loaded 29 earning_call chunks for ticker=AAPL from 2017-Jan-31-AAPL.txt\n",
      " Loaded 28 earning_call chunks for ticker=AAPL from 2019-Apr-30-AAPL.txt\n",
      " Loaded 26 earning_call chunks for ticker=AAPL from 2017-Nov-02-AAPL.txt\n",
      " Loaded 31 earning_call chunks for ticker=AAPL from 2016-Oct-25-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2016-Jul-26-AAPL.txt\n",
      " Loaded 27 earning_call chunks for ticker=AAPL from 2017-May-02-AAPL.txt\n",
      " Loaded 32 earning_call chunks for ticker=AAPL from 2019-Jul-30-AAPL.txt\n",
      " Loaded 31 earning_call chunks for ticker=AAPL from 2019-Jan-29-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2018-Jul-31-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2018-Feb-01-AAPL.txt\n",
      " Loaded 33 earning_call chunks for ticker=AAPL from 2018-Nov-01-AAPL.txt\n",
      " Loaded 30 earning_call chunks for ticker=AAPL from 2020-Apr-30-AAPL.txt\n",
      " Loaded 125 10K chunks for ticker=AMZN from AMZN-2023-10K.pdf\n",
      " Loaded 117 10K chunks for ticker=AMZN from AMZN-2022-10K.pdf\n",
      " Loaded 118 10K chunks for ticker=AMZN from AMZN-2021-10K.pdf\n",
      " Loaded 20 earning_call chunks for ticker=AMZN from 2020-Jan-30-AMZN.txt\n",
      " Loaded 28 earning_call chunks for ticker=AMZN from 2016-Apr-28-AMZN.txt\n",
      " Loaded 19 earning_call chunks for ticker=AMZN from 2019-Oct-24-AMZN.txt\n",
      " Loaded 24 earning_call chunks for ticker=AMZN from 2020-Apr-30-AMZN.txt\n",
      " Loaded 22 earning_call chunks for ticker=AMZN from 2019-Apr-25-AMZN.txt\n",
      " Loaded 17 earning_call chunks for ticker=AMZN from 2017-Jul-27-AMZN.txt\n",
      " Loaded 20 earning_call chunks for ticker=AMZN from 2018-Jul-26-AMZN.txt\n",
      " Loaded 20 earning_call chunks for ticker=AMZN from 2018-Oct-25-AMZN.txt\n",
      " Loaded 30 earning_call chunks for ticker=AMZN from 2016-Jan-28-AMZN.txt\n",
      " Loaded 21 earning_call chunks for ticker=AMZN from 2018-Feb-01-AMZN.txt\n",
      " Loaded 23 earning_call chunks for ticker=AMZN from 2020-Jul-30-AMZN.txt\n",
      " Loaded 21 earning_call chunks for ticker=AMZN from 2019-Jul-25-AMZN.txt\n",
      " Loaded 21 earning_call chunks for ticker=AMZN from 2017-Apr-27-AMZN.txt\n",
      " Loaded 20 earning_call chunks for ticker=AMZN from 2019-Jan-31-AMZN.txt\n",
      " Loaded 19 earning_call chunks for ticker=AMZN from 2018-Apr-26-AMZN.txt\n",
      " Loaded 22 earning_call chunks for ticker=AMZN from 2016-Oct-27-AMZN.txt\n",
      " Loaded 21 earning_call chunks for ticker=AMZN from 2017-Feb-02-AMZN.txt\n",
      " Loaded 26 earning_call chunks for ticker=AMZN from 2016-Jul-28-AMZN.txt\n",
      " Loaded 19 earning_call chunks for ticker=AMZN from 2017-Oct-26-AMZN.txt\n",
      "Loaded a total of 1647 chunks from 6 10Ks and 38 earning calls for 2 tickers.\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "id": "c74e4532",
   "metadata": {},
   "source": "## Redis as a Langchain Retriever\n"
  },
  {
   "cell_type": "code",
   "id": "e50c9efe-4abe-42fa-b35a-05eeeede9ec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:55.529015Z",
     "start_time": "2024-06-13T18:15:55.514659Z"
    }
   },
   "source": [
    "from langchain_community.vectorstores import Redis as LangChainRedis\n",
    "from utils import create_langchain_schemas_from_redis_schema\n",
    "\n",
    "index_name = 'langchain'\n",
    "\n",
    "vec_schema , main_schema = create_langchain_schemas_from_redis_schema('sec_index.yaml')\n",
    "\n",
    "rds = LangChainRedis.from_existing_index( embedding = embeddings, \n",
    "                                          index_name = index_name, \n",
    "                                          schema = main_schema)\n",
    "redis_retriever = rds.as_retriever()\n"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test if the Redis index is working and returning relevant document.",
   "id": "fcc76c0d6a83a135"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:15:55.555125Z",
     "start_time": "2024-06-13T18:15:55.529548Z"
    }
   },
   "cell_type": "code",
   "source": "rds.similarity_search(query=\"Apple in 2022\", k=4, distance_threshold=0.8)",
   "id": "39b95a9507cbf6a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The Companys global operations are subject to complex and changing laws and regulations on subjects, including antitrust; privacy, data security and data localization; consumer protection; advertising, sales, billing and e-commerce; financial services and technology; product liability; intellectual property ownership and infringement; digital platforms; internet, telecommunications, and mobile communications; media, television, film and digital content; availability of third-party software applications and services; labor and employment; anticorruption; import, export and trade; foreign exchange controls and cash repatriation restrictions; antimoney laundering; foreign ownership and investment; tax; and environmental, health and safety, including electronic waste, recycling, and climate change.\\n\\nApple Inc. | 2022 Form 10-K | 13', metadata={'id': 'chunk:AAPL-2022-10K.pdf-d603eef9-2046-408f-b64e-4051cbcc2d2d', 'chunk_id': 'AAPL-2022-10K.pdf-d603eef9-2046-408f-b64e-4051cbcc2d2d', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content='The following discussion should be read in conjunction with the consolidated financial statements and accompanying notes included in Part II, Item 8 of this Form 10-K. This section of this Form 10-K generally discusses 2022 and 2021 items and year-to-year comparisons between 2022 and 2021. Discussions of 2020 items and year-to-year comparisons between 2021 and 2020 are not included in this Form 10-K, and can be found in Managements Discussion and Analysis of Financial Condition and Results of Operations in Part II, Item 7 of the Companys Annual Report on Form 10-K for the fiscal year ended September 25, 2021.\\n\\nFiscal Year Highlights\\n\\nFiscal 2022 Highlights\\n\\nTotal net sales increased 8% or $28.5 billion during 2022 compared to 2021, driven primarily by higher net sales of iPhone, Services and Mac. The weakness in foreign currencies relative to the U.S. dollar had an unfavorable year-over-year impact on all Products and Services net sales during 2022.\\n\\nThe Company announces new product, service and software offerings at various times during the year. Significant announcements during fiscal 2022 included the following:\\n\\nFirst Quarter 2022:\\n\\n\\n\\nUpdated MacBook Pro 14 and MacBook Pro 16, powered by the Apple M1 Pro or M1 Max chip; and Third generation of AirPods.\\n\\nSecond Quarter 2022:\\n\\n  \\n\\nUpdated iPhone SE with 5G technology; All-new Mac Studio, powered by the Apple M1 Max or M1 Ultra chip; All-new Studio Display; and Updated iPad Air with 5G technology, powered by the Apple M1 chip.\\n\\nThird Quarter 2022:\\n\\n \\n\\nUpdated MacBook Air and MacBook Pro 13, both powered by the Apple M2 chip; iOS 16, macOS Ventura, iPadOS 16 and watchOS 9, updates to the Companys operating systems; and Apple Pay Later, a buy now, pay later service.\\n\\nFourth Quarter 2022:\\n\\n \\n\\niPhone 14, iPhone 14 Plus, iPhone 14 Pro and iPhone 14 Pro Max; Second generation of AirPods Pro; and Apple Watch Series 8, updated Apple Watch SE and all-new Apple Watch Ultra.\\n\\nIn April 2022, the Company announced an increase to its Program authorization from $315 billion to $405 billion and raised its quarterly dividend from $0.22 to $0.23 per share beginning in May 2022. During 2022, the Company repurchased $90.2 billion of its common stock and paid dividends and dividend equivalents of $14.8 billion.\\n\\nCOVID-19', metadata={'id': 'chunk:AAPL-2022-10K.pdf-47718408-7f9a-4f80-b281-9fac9e99a5fb', 'chunk_id': 'AAPL-2022-10K.pdf-47718408-7f9a-4f80-b281-9fac9e99a5fb', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content='In May 2023, the Company announced a new share repurchase program of up to $90 billion and raised its quarterly dividend from $0.23 to $0.24 per share beginning in May 2023. During 2023, the Company repurchased $76.6 billion of its common stock and paid dividends and dividend equivalents of $15.0 billion.\\n\\nMacroeconomic Conditions\\n\\nMacroeconomic conditions, including ination, changes in interest rates, and currency uctuations, have directly and indirectly impacted, and could in the future materially impact, the Companys results of operations and nancial condition.\\n\\nApple Inc. | 2023 Form 10-K | 20\\n\\nSegment Operating Performance\\n\\nThe following table shows net sales by reportable segment for 2023, 2022 and 2021 (dollars in millions):\\n\\n2023\\n\\nChange\\n\\n2022\\n\\nChange\\n\\nNet sales by reportable segment:\\n\\nAmericas Europe Greater China Japan Rest of Asia Pacic\\n\\nTotal net sales\\n\\n$\\n\\n$\\n\\n162,560 94,294 72,559 24,257 29,615 383,285\\n\\n(4)% $ (1)% (2)% (7)% 1 % (3)% $\\n\\n169,658 95,118 74,200 25,977 29,375 394,328\\n\\n11 % $ 7 % 9 % (9)% 11 %\\n\\n8 % $\\n\\nAmericas\\n\\nAmericas net sales decreased 4% or $7.1 billion during 2023 compared to 2022 due to lower net sales of iPhone and Mac, partially oset by higher net sales of Services.\\n\\nEurope\\n\\nEurope net sales decreased 1% or $824 million during 2023 compared to 2022. The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Europe net sales, which consisted primarily of lower net sales of Mac and Wearables, Home and Accessories, partially oset by higher net sales of iPhone and Services.\\n\\nGreater China\\n\\nGreater China net sales decreased 2% or $1.6 billion during 2023 compared to 2022. The weakness in the renminbi relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Greater China net sales, which consisted primarily of lower net sales of Mac and iPhone.\\n\\nJapan\\n\\nJapan net sales decreased 7% or $1.7 billion during 2023 compared to 2022. The weakness in the yen relative to the U.S. dollar accounted for more than the entire year-over-year decrease in Japan net sales, which consisted primarily of lower net sales of iPhone, Wearables, Home and Accessories and Mac.\\n\\nRest of Asia Pacic', metadata={'id': 'chunk:AAPL-2023-10K.pdf-14f045f5-72b3-48db-afb3-3de093056a67', 'chunk_id': 'AAPL-2023-10K.pdf-14f045f5-72b3-48db-afb3-3de093056a67', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
       " Document(page_content=\"Coming this fall, Apple TV+ will be new home for world's most creative story tellers, featuring exclusive: 1. Original shows. 2. Movies. 3. Documentaries. 4. Several Major Product Introductions: 1. iMac: 1. Launched new more powerful iMac with dramatic increases in compute and graphics performance, making it great update for consumers and pros alike. 2. For Mac business overall, faced some processor constraints, leading to 5% revenue decline vs. last year. 1. Believes that Mac revenue would have been up vs. last year without those constraints. 2. Does not believe this challenge will have significant impact on 3Q results. 2. iPad: 1. Returned to growth in Greater China. 1. Generated strong double-digit growth in each of Co.'s other geographic segments. 2. Great iPad results were driven primarily by strong customer response to iPad Pro. 3. Late in qtr., launched all-new iPad Air with ultra-thin design, Apple Pencil support and high-end performance powered by A12 Bionic chip. 4. Introduced new iPad Mini, major upgrade for iPad fans who love ultra-portable design. 1. Like new iPad Air, it delivers power of A12 Bionic and support for Apple Pencil. 3. AirPods: 1. Last month, introduced new AirPods. 1. Second generation of world's most popular wireless headphones. 2. Demand has been incredible. 2. With new Co.-designed H1 chip, new AirPods deliver faster connect times, more talk time and convenience of hands-free Hey Siri. 4.\", metadata={'id': 'chunk:2019-Apr-30-AAPL.txt-013b42f9-7592-4d1e-bf54-bda547debe60', 'chunk_id': '2019-Apr-30-AAPL.txt-013b42f9-7592-4d1e-bf54-bda547debe60', 'source_doc': '2019-Apr-30-AAPL.txt', 'doc_type': 'earning_call', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "id": "225d2277-45b2-4ae8-a7d6-62b07fb4a002",
   "metadata": {},
   "source": "## Create different components of your Graph pipeline"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### RAG Chain\n",
    "This component is responsible for genereting the final answer given a context we construct using our retrival process "
   ],
   "id": "85f9d6d70a7d2349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:02.172260Z",
     "start_time": "2024-06-13T18:15:55.555716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate,PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "def get_gen_rag_chain():\n",
    "    # LLM\n",
    "    gen_llm = ChatOllama(model=\"llama3\", temperature=0)\n",
    "    gen_local_prompt = PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "\n",
    "    # Chain\n",
    "    gen_rag_chain = gen_local_prompt | gen_llm | StrOutputParser()\n",
    "    return gen_rag_chain\n",
    "\n",
    "q=\"what is the deferred apple revenue in 2022?\"\n",
    "context = \"\"\"As of September 24, 2022 and September 25, 2021, \n",
    "            the Company had total deferred revenue of $12.4 \n",
    "            billion and $11.9 billion, respectively. As of \n",
    "            September 24, 2022, the Company expects 64% of \n",
    "            total deferred revenue to be realized in less \"\"\"\n",
    "\n",
    "my_gen_rag_chain = get_gen_rag_chain()\n",
    "    # Run Gen LLM\n",
    "response = my_gen_rag_chain.invoke({\"context\": context, \"question\": q})\n",
    "print(response)"
   ],
   "id": "ae6b410735d14731",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I don't know the specific deferred apple revenue for 2022. However, I can tell you that as of September 24, 2022, Apple had total deferred revenue of $12.4 billion.\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Query Understanding\n",
    "This component is using our basic `llama3` LLM to analyze user's questions and queries and does several tasks in one-shot:\n",
    "   - determines whether a question is relevant to the domain of finance\n",
    "   - determines if the question can be answered better by looking into `10k`s or `earning_calls` \n",
    "   - determines if the question is generally looking for a numeric answer or an explanation. This could be crucial information in the downstream components where we go to find the right answer or verify our answers. An explanation for example is more textual and can be measured in terms cosine similarity;however, a numeric answer can be verified by running a tool that does mathematical calculations that is result of a program that get run, for example a [PAL chain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#).   "
   ],
   "id": "17fecb700639afe1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:13.428479Z",
     "start_time": "2024-06-13T18:16:02.176347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def get_question_analyzer():\n",
    "    question_classifier_llm = ChatOllama(model=\"llama3\", format=\"json\", temperature=0)\n",
    "    question_classifier_prompt = PromptTemplate(\n",
    "        template=\"\"\"Your task is to analyze and classify a question and formulate a new question related to the topic that you found. You have to determine if the answer for the question can be found in \"earning_calls\" or \"10K\" financial filings. So choose either \"earning_calls\" or \"10K\" as the assigned class. If you are unsure assign `None`. Assign three classes of 'earning_call' or '10K' or 'None' as a JSON with a single key 'question_class'. Also add a new key called 'new_question' and try to rewrite the given question based on the class you detected. If the detected class is 'None' or your could find a relevance of the questions to those 'earning_calls' or '10K' return 'None' as the new question.\n",
    "          \n",
    "        \n",
    "        Also add a new field in the JSON called 'question_type'. You have to determine if the answer to user's question is likely to be a number or an explanation. if the answer to the question is likely to be number assign 'numeric' and if the answer is likely to be explanation assign `explain` to the 'question_type'.\n",
    "        \n",
    "       Also add a new field in the JSON called 'question_relevancy'. You have to determine if user's question is relevant to the domain of finance or not.If the question is is not relevant to the domain of finance give the value of 'not_relevant' and if it is relevant to the domain of finance give the value of 'relevant'.    \n",
    "        \n",
    "        Only return a valid JSON objects as your response. If you have new information or notes, add a new field in the JSON called `note` and add your explanation in that `note` field.: \\n\\n {question}.  \\n \"\"\",\n",
    "        input_variables=[\"question\"],\n",
    "    )\n",
    "    question_analyzer = question_classifier_prompt | question_classifier_llm | JsonOutputParser()\n",
    "    return question_analyzer\n",
    "\n",
    "my_question_analyzer = get_question_analyzer()\n",
    "my_question_analyzer.invoke({\"question\": \"what is the aapl revenue in 2022?\"})"
   ],
   "id": "5762c816db4168eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_class': '10K',\n",
       " 'new_question': \"What are Apple's reported revenues for 2022?\",\n",
       " 'question_type': 'numeric',\n",
       " 'question_relevancy': 'relevant'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:23.863458Z",
     "start_time": "2024-06-13T18:16:13.430883Z"
    }
   },
   "cell_type": "code",
   "source": "my_question_analyzer.invoke({\"question\": \"what was the mood of Tim Cook in the earning calls of 2022?\"})",
   "id": "b4abf26d92fa5a21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_class': 'earning_calls',\n",
       " 'new_question': \"What were the key takeaways from Apple's CEO, Tim Cook, during their 2022 earnings calls?\",\n",
       " 'question_type': 'explain',\n",
       " 'question_relevancy': 'relevant'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:35.491868Z",
     "start_time": "2024-06-13T18:16:23.865728Z"
    }
   },
   "cell_type": "code",
   "source": "my_question_analyzer.invoke({\"question\": \"Why colorless green ideas are sleeping furiously?\"})",
   "id": "fbb7f12ecd289a63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_class': 'None',\n",
       " 'new_question': 'None',\n",
       " 'question_type': 'explain',\n",
       " 'question_relevancy': 'not_relevant',\n",
       " 'note': 'This question is not related to finance and does not have a clear answer. It appears to be a philosophical or linguistic puzzle.'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Retrieval Grader\n",
    "This is a simple component that determines whether a retrieved document is relevant to user's question or not suing a simple strategy. As we demonstrate below, this is not very effective. Firstly, if the documents are presented using a proper embedding model, then the fact that are semantically relevant to user's query is higher than this simple strategy. Here we simply want to show this component as placeholder. We recommend you to either replace this component with a fine-tuned LLM-based reranker or use a Learning To Rank (LTR) model. "
   ],
   "id": "82e0b1a0bf5809f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:43.008868Z",
     "start_time": "2024-06-13T18:16:35.493713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Retrieval Grader\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def get_retrieval_grader():\n",
    "    retrieval_grader_llm = ChatOllama(model='llama3', format=\"json\", temperature=0)\n",
    "\n",
    "    retrieval_grader_prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "        Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "        Here is the user question: {input} \\n\n",
    "        If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "        It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "        Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "        Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "        input_variables=[\"input\", \"document\"],\n",
    "    )\n",
    "    \n",
    "    retrieval_grader = retrieval_grader_prompt | retrieval_grader_llm | JsonOutputParser()\n",
    "    return retrieval_grader\n",
    "\n",
    "my_retrieval_grader = get_retrieval_grader()\n",
    "\n",
    "question = \"apple revenue in 2022\"\n",
    "docs = redis_retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[0].page_content\n",
    "print(my_retrieval_grader.invoke({\"input\": question, \"document\": doc_txt}))"
   ],
   "id": "6d636fcc416e5b53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "score_threshold is deprecated. Use distance_threshold instead.score_threshold should only be used in similarity_search_with_relevance_scores.score_threshold will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:45.595796Z",
     "start_time": "2024-06-13T18:16:43.010538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_retrieval_grader.invoke({\"input\": \"apple revenue in 2022\", \"document\": \"\"\"\n",
    "We serve consumers through our online and physical stores and focus on selection, price, and convenience. We design our\n",
    "stores to enable hundreds of millions of unique products to be sold by us and by third parties across dozens of product categories.\n",
    "Customers access our offerings through our websites, mobile apps, Alexa, devices, streaming, and physically visiting our stores. We\n",
    "also manufacture and sell electronic devices, including Kindle, Fire tablet, Fire TV , Echo, Ring, and other devices, and we develop\n",
    "and produce media content. We seek to offer our customers low prices, fast and free delivery, easy-to-use functionality, and timely\n",
    "customer service. In addition, we offer Amazon Prime, a membership program that includes unlimited free shipping on over 100\n",
    "million items, access to unlimited streaming of tens of thousands of movies and TV episodes, including Amazon Original content,\n",
    "and other benefits.\n",
    "\"\"\"})"
   ],
   "id": "13b1ec0b06e274bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'no'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.156789Z",
     "start_time": "2024-06-13T18:16:45.597100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_retrieval_grader.invoke({\"input\": \"Amazon's revenue in 2022\", \"document\": \"\"\"\n",
    "We serve consumers through our online and physical stores and focus on selection, price, and convenience. We design our\n",
    "stores to enable hundreds of millions of unique products to be sold by us and by third parties across dozens of product categories.\n",
    "Customers access our offerings through our websites, mobile apps, Alexa, devices, streaming, and physically visiting our stores. We\n",
    "also manufacture and sell electronic devices, including Kindle, Fire tablet, Fire TV , Echo, Ring, and other devices, and we develop\n",
    "and produce media content. We seek to offer our customers low prices, fast and free delivery, easy-to-use functionality, and timely\n",
    "customer service. In addition, we offer Amazon Prime, a membership program that includes unlimited free shipping on over 100\n",
    "million items, access to unlimited streaming of tens of thousands of movies and TV episodes, including Amazon Original content,\n",
    "and other benefits.\n",
    "\"\"\"})"
   ],
   "id": "1434635cf6709c5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As you can see this grader, grades this document as relevant. It seems to be relevant to Aamzon but there is no information around revenue.",
   "id": "829df8ffee98f5bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Target Query Construction and Translation\n",
    "To increase the precision of the retrieval and limit the search space - given the fact you might be dealing with billions of documents - we recommend to take advantage of Redis Hybrid search and automatically construct filters based on your metadata. A Simple vector representation simply does not cut it. To demonstrate that consider these two queries:\n",
    "`what was the performance of amzn in 2021?` and `what was the performance of amzn in 2022`. The cosine similarity of these two queries are:\n",
    " "
   ],
   "id": "1b5e5bf644e35239"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.357758Z",
     "start_time": "2024-06-13T18:16:47.159183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "em1 = np.array(embeddings.embed_query(\"what was the performance of amzn in 2021?\"))\n",
    "em2 = np.array(embeddings.embed_query(\"what was the performance of amzn in 2022?\"))\n",
    "cosine = np.dot(em1,em2)/(norm(em1)*norm(em2))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ],
   "id": "b1c6edecf084ee00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9115875535206758\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.360145Z",
     "start_time": "2024-06-13T18:16:47.358402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cosine = np.dot(em1,em1)/(norm(em1)*norm(em1))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ],
   "id": "45eac14205620a14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 1.0000000000000002\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The answer to these questions are wildly different. But the high similarity between two queries will result in documents that might be from different years. However, if you apply a simple date NER and filter the document source year, you will eliminate that problem. This problem also could appear in geospatial search where a longitude and latitude of two points could point to the same location but with different precision. However, 12.12412414 is textually different from 12.1. So again you can translate to a proper geo-filter (which Redis supports).   ",
   "id": "70244a316e5160ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So here we have a built a simple toy NER using spacy, and did a simple translation; again as placeholder for a component that we feel is necessary and will leave it for you to build you own NER (using your internal metadata and language based on the method of your choice)",
   "id": "7843fb814b811882"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.370258Z",
     "start_time": "2024-06-13T18:16:47.360691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from helpers.custom_ners import * \n",
    "def custom_redis_query_translator(q):\n",
    "    filters = get_redis_filters(q)\n",
    "    return filters\n",
    "\n",
    "custom_redis_query_translator(\"what was the performance of amzn in 2021 in nasdaq?\")"
   ],
   "id": "e266c6cdb624601e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ticker:{AMZN} | @exchange:{NASDAQ}'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.377063Z",
     "start_time": "2024-06-13T18:16:47.371171Z"
    }
   },
   "cell_type": "code",
   "source": "custom_redis_query_translator(\"what was the performance of Apple Inc in 2021?\")",
   "id": "b91bce77c915d3b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@company_name:{APPLE INC}'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Putting it all together:  build your RAG logic inside a Graph\n",
    "Now that we have all the components for our RAG logic we will connect them through a graph."
   ],
   "id": "89c2fc571ea60f6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.381059Z",
     "start_time": "2024-06-13T18:16:47.377650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing import Annotated, TypedDict, Union, Sequence, List\n",
    "from langchain.agents import create_react_agent\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    filters : str\n",
    "    question_relevancy: str\n",
    "    question_class: str\n",
    "    question_type: str\n",
    "    alternate_question: str\n",
    "    question_note: str\n",
    "    rewrite_num: int\n",
    "    generation: str\n",
    "    documents: List[str]\n"
   ],
   "id": "8f03f9e92f8596f6",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:47.389885Z",
     "start_time": "2024-06-13T18:16:47.381609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import Literal\n",
    "from custom_ners import get_redis_filters\n",
    "from utils import *\n",
    "\n",
    "MAX_RETRY_COUNT = 2\n",
    "MAX_TOKEN_LIMIT = 1000 #char\n",
    "TOP_DOC_LIMIT = 2 \n",
    "\n",
    "\n",
    "### Edges\n",
    "def check_retrieval_relevancy(state) -> Literal[\"generate\", \"rewrite\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question or not.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    input = state[\"input\"]\n",
    "    documents = state[\"documents\"]\n",
    "    retries = state[\"rewrite_num\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = my_retrieval_grader.invoke({\"input\": input, \"document\": d})\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    \n",
    "    if len(documents) - len(filtered_docs) > 2 :\n",
    "        return \"generate\"\n",
    "    elif retries < MAX_RETRY_COUNT:\n",
    "        return \"rewrite\"\n",
    "    elif retries >= MAX_RETRY_COUNT:\n",
    "        return \"generate\"\n",
    "    \n",
    "### Edges\n",
    "def check_question_relevancy(state) -> Literal[\"generate\", \"retrieve\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the asked question is relevant to our domain and if retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        str: A decision for whether the documents are relevant or not\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    question_relevancy = state[\"question_relevancy\"]\n",
    "    if question_relevancy == 'not_relevant':\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"retrieve\"\n",
    "\n",
    "### Nodes\n",
    "\n",
    "def query_understanding(state):\n",
    "    \"\"\"\n",
    "    Analyzes the input query for better retrieval.\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "        dict: The updated state with the result of query analysis\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"--- QUERY Analysis ---\")\n",
    "    def combine_filters(inferred_filters, doc_type_filter=\"10K\", filter_strategy=\"AND\"):\n",
    "        if inferred_filters is None:\n",
    "            return \"@doc_type:{\"+f\"{doc_type_filter}\"+\"}\"\n",
    "        else:\n",
    "            return \"@doc_type:{\"+f\"{doc_type_filter}\"+\"} \" + filter_strategy +f\" ({inferred_filters})\"\n",
    "            \n",
    "        \n",
    "    question = state[\"input\"]\n",
    "    rewrite_num = state[\"rewrite_num\"]\n",
    "    if rewrite_num is None:\n",
    "        rewrite_num = 1\n",
    "    else:\n",
    "        rewrite_num = int(state[\"rewrite_num\"]) + 1\n",
    "    \n",
    "    q_filters = custom_redis_query_translator(question)\n",
    "    question_analysis = my_question_analyzer.invoke({\"question\": question})\n",
    "    print(f\"---QUERY rewrite---question_analysis={question_analysis}\")\n",
    "    question_class = question_analysis[\"question_class\"]\n",
    "    \n",
    "    if question_class != \"None\":\n",
    "        print(f\"---Question Class: Question is Related to {question_class}---\")\n",
    "        applied_filters = combine_filters(q_filters, doc_type_filter=question_class)\n",
    "    else:\n",
    "        applied_filters = combine_filters(q_filters)\n",
    "        \n",
    "    new_question = question_analysis[\"new_question\"]   \n",
    "    \n",
    "    if new_question != \"None\":\n",
    "        print(f\"---Question Analysis: alternate_question is {new_question}---\")\n",
    "        alternate_question = new_question\n",
    "    else:\n",
    "        alternate_question = None\n",
    "    \n",
    "    question_note = None    \n",
    "    if question_analysis.get('note') is not None:\n",
    "        question_note = question_analysis['note']\n",
    "        \n",
    "        \n",
    "    return {\"filters\": applied_filters, \n",
    "            \"question_class\": question_class, \n",
    "            \"question_type\": question_analysis[\"question_type\"],\n",
    "            \"question_relevancy\": question_analysis[\"question_relevancy\"],\n",
    "            \"alternate_question\": alternate_question,\n",
    "            \"question_note\": question_note,\n",
    "            \"rewrite_num\": rewrite_num\n",
    "            }\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "def redis_retriever(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from Redis.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE FROM REDIS---\")\n",
    "    input = state[\"input\"]\n",
    "    alternate_question = state[\"alternate_question\"]\n",
    "    retries = state[\"rewrite_num\"]\n",
    "    filters = state[\"filters\"]\n",
    "    query = input\n",
    "    print(f\"\\t---RETRIEVE FROM REDIS= query={input} alternate_question={alternate_question}- retries={retries}\")\n",
    "    if alternate_question is not None and retries > 1:\n",
    "        query = alternate_question    \n",
    "     \n",
    "    if filters is None:\n",
    "        documents = rds.similarity_search(query=query, k=4, distance_threshold=0.8)\n",
    "    else:\n",
    "        documents = rds.similarity_search(query=query, k=4, distance_threshold=0.8, filter=filters)\n",
    "        \n",
    "    return {\"documents\": documents}\n",
    "\n",
    "    \n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (messages): The current state\n",
    "\n",
    "    Returns:\n",
    "         dict: The updated state with re-phrased question\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---GENERATE---\")\n",
    "    final_docs = state[\"documents\"]\n",
    "    final_question = state[\"input\"]\n",
    "    question_relevancy = state[\"question_relevancy\"]\n",
    "    note = None\n",
    "    if state.get('note') is None:\n",
    "        note =state[\"question_note\"]\n",
    "    \n",
    "    final_context = \"\"\n",
    "    if question_relevancy == \"not_relevant\":\n",
    "        final_context = f\"Your question does not seem to be relevant to finance. Please only ask questions that are relevant to financials of companies that are usually reported in 10K or earning calls.\"\n",
    "        if note is not None:\n",
    "            final_context = final_context + f\"\\n\\n{note}\"\n",
    "    elif question_relevancy == \"relevant\" and final_docs is not None and len(final_docs) > 0:\n",
    "        final_context = str(\"\\n\".join(format_docs(final_docs[:TOP_DOC_LIMIT])))[:MAX_TOKEN_LIMIT]\n",
    "       \n",
    "    print(f\"DEBUG:GENERATE === question={final_question}\")\n",
    "    print(f\"DEBUG:GENERATE === context={final_context}\")\n",
    "    \n",
    "    # Run Gen LLM\n",
    "    generated_answer = my_gen_rag_chain.invoke({\"context\": final_context, \"question\": final_question})\n",
    "    \n",
    "    print(f\"RFD-DEBUG:GENERATE=== generation={generated_answer}\")\n",
    "    return {\"messages\": [generated_answer], \"generation\": generated_answer}"
   ],
   "id": "993ba7ced09fdc22",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T18:16:48.645527Z",
     "start_time": "2024-06-13T18:16:47.390426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"query_understanding_node\", query_understanding)\n",
    "workflow.add_node(\"redis_retriever_node\", redis_retriever)\n",
    "workflow.add_node(\"generate_node\", generate)\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"redis_retriever_node\",\n",
    "    check_retrieval_relevancy,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"rewrite\": \"query_understanding_node\",\n",
    "        \"generate\": \"generate_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"query_understanding_node\",\n",
    "    check_question_relevancy,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"retrieve\": \"redis_retriever_node\",\n",
    "        \"generate\": \"generate_node\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"generate_node\", END)\n",
    "\n",
    "workflow.set_entry_point(\"query_understanding_node\")\n",
    "\n",
    "# Compile\n",
    "graphapp = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "try:\n",
    "    display(Image(graphapp.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass\n"
   ],
   "id": "b2acd602638ce906",
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-13T18:16:48.646495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"input\":\"What was the deferred revenue of aapl in 2022?\",\n",
    "}\n",
    "for output in graphapp.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"Output from node '{key}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ],
   "id": "7823529303b98dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- QUERY Analysis ---\n",
      "---QUERY rewrite---question_analysis={'question_class': '10K', 'new_question': 'What is the deferred revenue reported by AAPL in their 2022 financial filings?', 'question_type': 'numeric', 'question_relevancy': 'relevant'}\n",
      "---Question Class: Question is Related to 10K---\n",
      "---Question Analysis: alternate_question is What is the deferred revenue reported by AAPL in their 2022 financial filings?---\n",
      "\"Output from node 'query_understanding_node':\"\n",
      "'---'\n",
      "{ 'alternate_question': 'What is the deferred revenue reported by AAPL in '\n",
      "                        'their 2022 financial filings?',\n",
      "  'filters': '@doc_type:{10K} AND (@ticker:{AAPL})',\n",
      "  'question_class': '10K',\n",
      "  'question_note': None,\n",
      "  'question_relevancy': 'relevant',\n",
      "  'question_type': 'numeric',\n",
      "  'rewrite_num': 1}\n",
      "'\\n---\\n'\n",
      "---RETRIEVE FROM REDIS---\n",
      "\t---RETRIEVE FROM REDIS= query=What was the deferred revenue of aapl in 2022? alternate_question=What is the deferred revenue reported by AAPL in their 2022 financial filings?- retries=1\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "\"Output from node 'redis_retriever_node':\"\n",
      "'---'\n",
      "{ 'documents': [ Document(page_content='The Companys proportion of net sales by disaggregated revenue source was generally consistent for each reportable segment in Note 11, Segment Information and Geographic Data for 2022, 2021 and 2020, except in Greater China, where iPhone revenue represented a moderately higher proportion of net sales in 2022 and 2021.\\n\\nAs of September 24, 2022 and September 25, 2021, the Company had total deferred revenue of $12.4 billion and $11.9 billion, respectively. As of September 24, 2022, the Company expects 64% of total deferred revenue to be realized in less than a year, 27% within one-to-two years, 7% within two-to-three years and 2% in greater than three years.\\n\\nApple Inc. | 2022 Form 10-K | 37\\n\\n2020\\n\\n137,781 28,622 23,724 30,620 53,768 274,515\\n\\nNote 3  Financial Instruments\\n\\nCash, Cash Equivalents and Marketable Securities\\n\\nThe following tables show the Companys cash, cash equivalents and marketable securities by significant investment category as of September 24, 2022 and September 25, 2021 (in millions):\\n\\n2022\\n\\nAdjusted Cost\\n\\nUnrealized Gains\\n\\nUnrealized Losses\\n\\nFair Value\\n\\nCash and Cash Equivalents\\n\\nCurrent Marketable Securities\\n\\nCash\\n\\n$\\n\\n18,546 $\\n\\n $\\n\\n $\\n\\n18,546 $\\n\\n18,546 $\\n\\n $\\n\\nLevel 1\\n\\n(1) :\\n\\nMoney market funds Mutual funds Subtotal (2) :\\n\\nLevel 2\\n\\n2,929 274\\n\\n3,203\\n\\n \\n\\n\\n\\n (47)\\n\\n(47)\\n\\n2,929 227\\n\\n3,156\\n\\n2,929 \\n\\n2,929\\n\\n 227\\n\\n227\\n\\nU.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\n25,134 5,823 16,948\\n\\n  2\\n\\n(1,725) (655) (1,201)\\n\\n23,409 5,168 15,749\\n\\n338  \\n\\n5,091 240 8,806\\n\\ndeposits\\n\\nCommercial paper Corporate debt securities Municipal securities Mortgage- and asset-backed\\n\\n2,067 718 87,148 921\\n\\n  9 \\n\\n  (7,707) (35)\\n\\n2,067 718 79,450 886\\n\\n1,805 28  \\n\\n262 690 9,023 266\\n\\nsecurities Subtotal\\n\\n22,553\\n\\n161,312\\n\\n\\n\\n11\\n\\n(2,593)\\n\\n(13,916)\\n\\n19,960\\n\\n147,407\\n\\n\\n\\n2,171\\n\\n53\\n\\n24,431\\n\\nTotal\\n\\n(3)\\n\\n$ 183,061 $\\n\\n11 $\\n\\n(13,963) $ 169,109 $\\n\\n23,646 $\\n\\n24,658 $\\n\\n2021\\n\\nCash\\n\\n$\\n\\nAdjusted Cost 17,305 $\\n\\nUnrealized Gains\\n\\n $\\n\\nUnrealized Losses\\n\\n $\\n\\nFair Value\\n\\n17,305 $\\n\\nCash and Cash Equivalents\\n\\n17,305 $\\n\\nCurrent Marketable Securities\\n\\n $\\n\\nLevel 1\\n\\n(1) :\\n\\nMoney market funds Mutual funds Subtotal (2) : Equity securities U.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\nLevel 2\\n\\n9,608 175\\n\\n9,783\\n\\n1,527 22,878 8,949 20,201\\n\\n 11\\n\\n11\\n\\n 102 2 211\\n\\n (1)\\n\\n(1)\\n\\n(564) (77) (64) (101)\\n\\n9,608 185\\n\\n9,793\\n\\n963 22,903 8,887 20,311\\n\\n9,608 ', metadata={'id': 'chunk:AAPL-2022-10K.pdf-9fadc857-63b6-49ce-b75e-f7cc76a621b5', 'chunk_id': 'AAPL-2022-10K.pdf-9fadc857-63b6-49ce-b75e-f7cc76a621b5', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
      "                 Document(page_content='As of September 30, 2023 and September 24, 2022, the Company had total deferred revenue of $12.1 billion and $12.4 billion, respectively. As of September 30, 2023, the Company expects 67% of total deferred revenue to be realized in less than a year, 25% within one-to-two years, 7% within two-to-three years and 1% in greater than three years.\\n\\nNote 3  Earnings Per Share\\n\\nThe following table shows the computation of basic and diluted earnings per share for 2023, 2022 and 2021 (net income in millions and shares in thousands):\\n\\n2023\\n\\n2022\\n\\n2021\\n\\nNumerator:\\n\\nNet income\\n\\n$\\n\\n96,995 $\\n\\n99,803 $\\n\\n94,680\\n\\nDenominator:\\n\\nWeighted-average basic shares outstanding Eect of dilutive share-based awards Weighted-average diluted shares\\n\\n15,744,231 68,316 15,812,547\\n\\n16,215,963 109,856 16,325,819\\n\\n16,701,272 163,647 16,864,919\\n\\nBasic earnings per share Diluted earnings per share\\n\\n$ $\\n\\n6.16 $ 6.13 $\\n\\n6.15 $ 6.11 $\\n\\n5.67 5.61\\n\\nApproximately 24 million restricted stock units (RSUs) were excluded from the computation of diluted earnings per share for 2023 because their eect would have been antidilutive.\\n\\nApple Inc. | 2023 Form 10-K | 35\\n\\nNote 4  Financial Instruments\\n\\nCash, Cash Equivalents and Marketable Securities\\n\\nThe following tables show the Companys cash, cash equivalents and marketable securities by signicant investment category as of September 30, 2023 and September 24, 2022 (in millions):\\n\\n2023\\n\\nCash Level 1:\\n\\nAdjusted Cost\\n\\n$ 28,359 $\\n\\nUnrealized Gains\\n\\nUnrealized Losses\\n\\nFair Value  $ 28,359 $\\n\\n $\\n\\nCash and Cash Equivalents\\n\\nCurrent Marketable Securities\\n\\nNon-Current Marketable Securities\\n\\n28,359 $\\n\\n $\\n\\n\\n\\nMoney market funds Mutual funds and equity securities\\n\\n481\\n\\n442\\n\\n\\n\\n12\\n\\n\\n\\n(26)\\n\\n481\\n\\n428\\n\\n481\\n\\n\\n\\n\\n\\n428\\n\\n\\n\\n\\n\\nSubtotal (1)\\n\\nLevel 2\\n\\n:\\n\\n923\\n\\n12\\n\\n(26)\\n\\n909\\n\\n481\\n\\n428\\n\\n\\n\\nU.S. Treasury securities U.S. agency securities Non-U.S. government securities Certicates of deposit and time deposits Commercial paper Corporate debt securities Municipal securities Mortgage- and asset-backed securities\\n\\n19,406 5,736\\n\\n17,533\\n\\n1,354 608 76,840 628\\n\\n \\n\\n6\\n\\n  6 \\n\\n(1,292) (600)\\n\\n(1,048)\\n\\n  (5,956) (26)\\n\\n18,114 5,136\\n\\n16,491\\n\\n1,354 608 70,890 602\\n\\n35 36\\n\\n\\n\\n1,034  20 \\n\\n5,468 271\\n\\n11,332\\n\\n320 608 12,627 192\\n\\n12,611 4,829\\n\\n5,159\\n\\n  58,243 410\\n\\n22,365\\n\\n6\\n\\n(2,735)\\n\\n19,636\\n\\n\\n\\n344\\n\\n19,292\\n\\nSubtotal\\n\\nTotal\\n\\n(2)\\n\\n144,470 $ 173,752 $\\n\\n18 30 $ (11,683) $ 162,099 $\\n\\n(11,657)\\n\\n132,831\\n\\n1,125\\n\\n29,965 $\\n\\n31,162 31,590 $\\n\\n100,544 100,544\\n\\n2022\\n\\nAdjusted Cost\\n\\nUnrealized Gains', metadata={'id': 'chunk:AAPL-2023-10K.pdf-fdb7d28c-f74e-482a-b62a-dd3927e507b8', 'chunk_id': 'AAPL-2023-10K.pdf-fdb7d28c-f74e-482a-b62a-dd3927e507b8', 'source_doc': 'AAPL-2023-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
      "                 Document(page_content='Research and Development\\n\\nThe year-over-year growth in R&D expense in 2022 was driven primarily by increases in headcount-related expenses and engineering program costs.\\n\\nSelling, General and Administrative\\n\\nThe year-over-year growth in selling, general and administrative expense in 2022 was driven primarily by increases in headcount- related expenses, advertising and professional services.\\n\\nApple Inc. | 2022 Form 10-K | 23\\n\\n2020\\n\\n69,461 35,495 104,956\\n\\n31.5 % 66.0 % 38.2 %\\n\\n2020 18,752\\n\\n7 %\\n\\n19,916\\n\\n7 %\\n\\n38,668\\n\\n14 %\\n\\nOther Income/(Expense), Net\\n\\nOther income/(expense), net (OI&E) for 2022, 2021 and 2020 was as follows (dollars in millions):\\n\\n2022\\n\\nChange\\n\\n2021\\n\\nChange\\n\\nInterest and dividend income Interest expense Other income/(expense), net\\n\\nTotal other income/(expense), net\\n\\n$\\n\\n$\\n\\n2,825 (2,931) (228) (334)\\n\\n$\\n\\n(229)% $\\n\\n2,843 (2,645) 60 258\\n\\n$\\n\\n(68)% $\\n\\nThe decrease in OI&E during 2022 compared to 2021 was due primarily to higher realized losses on debt securities, unfavorable fair value adjustments on equity securities and higher interest expense, partially offset by higher foreign exchange gains.\\n\\nProvision for Income Taxes\\n\\nProvision for income taxes, effective tax rate and statutory federal income tax rate for 2022, 2021 and 2020 were as follows (dollars in millions):\\n\\n2022\\n\\n2021\\n\\nProvision for income taxes Effective tax rate Statutory federal income tax rate\\n\\n$\\n\\n19,300\\n\\n16.2 % 21 %\\n\\n$\\n\\n14,527\\n\\n13.3 % 21 %\\n\\n$\\n\\nThe Companys effective tax rate for 2022 was lower than the statutory federal income tax rate due primarily to a lower effective tax rate on foreign earnings, tax benefits from share-based compensation and the impact of the U.S. federal R&D credit, partially offset by state income taxes. The Companys effective tax rate for 2021 was lower than the statutory federal income tax rate due primarily to a lower effective tax rate on foreign earnings, tax benefits from share-based compensation and foreign-derived intangible income deductions.\\n\\nThe Companys effective tax rate for 2022 was higher compared to 2021 due primarily to a higher effective tax rate on foreign earnings, including the impact to U.S. foreign tax credits as a result of regulatory guidance issued by the U.S. Department of the Treasury in 2022, and lower tax benefits from foreign-derived intangible income deductions and share-based compensation.\\n\\nLiquidity and Capital Resources', metadata={'id': 'chunk:AAPL-2022-10K.pdf-7bf1e8f6-aab2-4844-a3f7-45755e39a1f5', 'chunk_id': 'AAPL-2022-10K.pdf-7bf1e8f6-aab2-4844-a3f7-45755e39a1f5', 'source_doc': 'AAPL-2022-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'}),\n",
      "                 Document(page_content='Includes $6.7 billion of revenue recognized in 2021 that was included in deferred revenue as of September 26, 2020, $5.0 billion of revenue recognized in 2020 that was included in deferred revenue as of September 28, 2019, and $5.9 billion of revenue recognized in 2019 that was included in deferred revenue as of September 29, 2018.\\n\\nThe Companys proportion of net sales by disaggregated revenue source was generally consistent for each reportable segment in Note 11, Segment Information and Geographic Data for 2021, 2020 and 2019.\\n\\nApple Inc. | 2021 Form 10-K | 37\\n\\n2019\\n\\n142,381 25,740 21,280 24,482 46,291 260,174\\n\\nNote 3  Financial Instruments\\n\\nCash, Cash Equivalents and Marketable Securities\\n\\nThe following tables show the Companys cash, cash equivalents and marketable securities by significant investment category as of September 25, 2021 and September 26, 2020 (in millions):\\n\\n2021\\n\\nAdjusted Cost\\n\\nUnrealized Gains\\n\\nUnrealized Losses\\n\\nFair Value\\n\\nCash and Cash Equivalents\\n\\nCurrent Marketable Securities\\n\\nCash\\n\\n$\\n\\n17,305 $\\n\\n $\\n\\n $\\n\\n17,305 $\\n\\n17,305 $\\n\\n $\\n\\nLevel 1\\n\\n(1) :\\n\\nMoney market funds Mutual funds Subtotal (2) : Equity securities U.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\nLevel 2\\n\\n9,608 175\\n\\n9,783\\n\\n1,527 22,878 8,949 20,201\\n\\n 11\\n\\n11\\n\\n 102 2 211\\n\\n (1)\\n\\n(1)\\n\\n(564) (77) (64) (101)\\n\\n9,608 185\\n\\n9,793\\n\\n963 22,903 8,887 20,311\\n\\n9,608 \\n\\n9,608\\n\\n 3,596 1,775 390\\n\\n 185\\n\\n185\\n\\n963 6,625 1,930 3,091\\n\\ndeposits\\n\\nCommercial paper Corporate debt securities Municipal securities Mortgage- and asset-backed\\n\\n1,300 2,639 83,883 967\\n\\n  1,242 14\\n\\n  (267) \\n\\n1,300 2,639 84,858 981\\n\\n490 1,776  \\n\\n810 863 12,327 130\\n\\nsecurities Subtotal\\n\\n20,529\\n\\n162,873\\n\\n171\\n\\n1,742\\n\\n(124)\\n\\n(1,197)\\n\\n20,576\\n\\n163,418\\n\\n\\n\\n8,027\\n\\n775\\n\\n27,514\\n\\nTotal\\n\\n(3)\\n\\n$ 189,961 $\\n\\n1,753 $\\n\\n(1,198) $ 190,516 $\\n\\n34,940 $\\n\\n27,699 $\\n\\n2020\\n\\nCash\\n\\nLevel 1 Level 2\\n\\n(1)\\n\\n: Money market funds (2) :\\n\\n$\\n\\nAdjusted Cost 17,773 $ 2,171\\n\\nUnrealized Gains\\n\\n $ \\n\\nUnrealized Losses\\n\\n $ \\n\\nFair Value\\n\\n17,773 $ 2,171\\n\\nCash and Cash Equivalents\\n\\n17,773 $ 2,171\\n\\nCurrent Marketable Securities\\n\\n $ \\n\\nU.S. Treasury securities U.S. agency securities Non-U.S. government securities Certificates of deposit and time\\n\\n28,439 8,604 19,361\\n\\n331 8 275\\n\\n  (186)\\n\\n28,770 8,612 19,450\\n\\n8,580 2,009 255\\n\\n11,972 3,078 3,329\\n\\ndeposits\\n\\nCommercial paper Corporate debt securities Municipal securities Mortgage- and asset-backed\\n\\n10,399 11,226 76,937 1,001\\n\\n  1,834 22', metadata={'id': 'chunk:AAPL-2021-10K.pdf-2919e06a-bd32-47a7-abc0-600007fb630f', 'chunk_id': 'AAPL-2021-10K.pdf-2919e06a-bd32-47a7-abc0-600007fb630f', 'source_doc': 'AAPL-2021-10K.pdf', 'doc_type': '10K', 'ticker': 'AAPL', 'company_name': 'APPLE INC', 'sector': 'Information Technology', 'asset_class': 'Equity', 'location': 'United States', 'exchange': 'NASDAQ', 'currency': 'USD', 'market_value': '559365151.11', 'weight': '5.16', 'notional_value': '559365151.11', 'shares': '4305127', 'price': '129.93'})]}\n",
      "'\\n---\\n'\n",
      "--- QUERY Analysis ---\n",
      "---QUERY rewrite---question_analysis={'question_class': '10K', 'new_question': 'What is the deferred revenue reported by AAPL in their 2022 financial filings?', 'question_type': 'numeric', 'question_relevancy': 'relevant'}\n",
      "---Question Class: Question is Related to 10K---\n",
      "---Question Analysis: alternate_question is What is the deferred revenue reported by AAPL in their 2022 financial filings?---\n",
      "\"Output from node 'query_understanding_node':\"\n",
      "'---'\n",
      "{ 'alternate_question': 'What is the deferred revenue reported by AAPL in '\n",
      "                        'their 2022 financial filings?',\n",
      "  'filters': '@doc_type:{10K} AND (@ticker:{AAPL})',\n",
      "  'question_class': '10K',\n",
      "  'question_note': None,\n",
      "  'question_relevancy': 'relevant',\n",
      "  'question_type': 'numeric',\n",
      "  'rewrite_num': 2}\n",
      "'\\n---\\n'\n",
      "---RETRIEVE FROM REDIS---\n",
      "\t---RETRIEVE FROM REDIS= query=What was the deferred revenue of aapl in 2022? alternate_question=What is the deferred revenue reported by AAPL in their 2022 financial filings?- retries=2\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import pprint\n",
    "\n",
    "inputs2 = {\n",
    "    \"input\":\"Why colorless green ideas are furiously sleeping?\"\n",
    "}\n",
    "\n",
    "for output2 in graphapp.stream(inputs2):\n",
    "    for key2, value2 in output2.items():\n",
    "        pprint.pprint(f\"Output from node '{key2}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value2, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ],
   "id": "34f4fb3c09949739",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "inputs2 = {\n",
    "    \"input\":\"What was the mood of Tim Cook in 2020 earning calls?\"\n",
    "}\n",
    "\n",
    "for output2 in graphapp.stream(inputs2):\n",
    "    for key2, value2 in output2.items():\n",
    "        pprint.pprint(f\"Output from node '{key2}':\")\n",
    "        pprint.pprint(\"---\")\n",
    "        pprint.pprint(value2, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")"
   ],
   "id": "aa74afdcc4245394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "Implement\n",
    "- Multiple index routing scenarios where based on the detected `query_class` we run retrieval queries on different Redis indices.\n",
    "- Implement a Caching strategy using powerful and superfast Redis features, including `SemanticCache`.\n",
    "- Replace the `RelevancyGrader` by a proper reranking model and node.   "
   ],
   "id": "4b59f853531650fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "The problem of search is still an old problem, and it is about representation of your information and storing it and getting back what you search for via a retrieval method. In the new `RAG` paradigm, information representation is the vector representation. So the more you can capture the nuances of your data using better and better embedding models, the better the `Retrieval`. However, as demonstrated above, we still need to take advantage of our metadata to increase the accuracy and `Augment` the query and also augment the context that we present to the `Generation` component. And most recently, LLMs do a good job of generating proper answers in the target natural languages. The quality of LLMs and their awareness of the domain language increase the quality of generated response.   "
   ],
   "id": "6c18e5f6c0f3b7fe"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d0aaded7fca1c11",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
